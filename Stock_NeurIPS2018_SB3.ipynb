{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfv52r2G33jY"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/Stock_NeurIPS2018_SB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
        "\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Task Description](#0)\n",
        "* [2. Install Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. A List of Python Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download and Preprocess Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5. Build Market Environment in OpenAI Gym-style](#4)  \n",
        "    * [5.1. Data Split](#4.1)  \n",
        "    * [5.3. Environment for Training](#4.2)    \n",
        "* [6. Train DRL Agents](#5)\n",
        "* [7. Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Task Discription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "We train a DRL agent for stock trading. This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
        "\n",
        "We specify the state-action-reward as follows:\n",
        "\n",
        "* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes many features and learns by interacting with the market environment (usually by replaying historical data).\n",
        "\n",
        "* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
        "\n",
        "\n",
        "**Market environment**: 30 consituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period.\n",
        "\n",
        "\n",
        "The data for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Install Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. A list of Python packages \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPqeTTwoh1hn",
        "outputId": "23c28589-9d6f-4b8b-bf9e-9822e4ccea90"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'config'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig_tickers\u001b[39;00m \u001b[39mimport\u001b[39;00m DOW_30_TICKER\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menv_stocktrading\u001b[39;00m \u001b[39mimport\u001b[39;00m StockTradingEnv\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m DRLAgent\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m configure\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     DATA_SAVE_DIR,\n\u001b[1;32m     27\u001b[0m     TRAINED_MODEL_DIR,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     TODAY\n\u001b[1;32m     39\u001b[0m )\n",
            "File \u001b[0;32m~/Bureau/VSCode/Stock_drl/Stock_drl/module/models.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnoise\u001b[39;00m \u001b[39mimport\u001b[39;00m OrnsteinUhlenbeckActionNoise\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvec_env\u001b[39;00m \u001b[39mimport\u001b[39;00m DummyVecEnv\n\u001b[0;32m---> 18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfig\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39menv_stocktrading\u001b[39;00m \u001b[39mimport\u001b[39;00m StockTradingEnv\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocessor\u001b[39;00m \u001b[39mimport\u001b[39;00m data_split\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"../STOCK_DRL\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "from Processed import get_processed_data\n",
        "\n",
        "from module.yahoodownloader import YahooDownloader\n",
        "from module.preprocessor import FeatureEngineer, data_split\n",
        "from module.efficient_frontier import EfficientFrontier\n",
        "from module import helper\n",
        "from module.config_tickers import DOW_30_TICKER\n",
        "from module.env_stocktrading import StockTradingEnv\n",
        "from module.models import DRLAgent\n",
        "from module.logger import configure\n",
        "from module.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        "    YESTERDAY,\n",
        "    TODAY\n",
        ")\n",
        "\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3 import DDPG\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3 import TD3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RtUc_ofKmpdy"
      },
      "outputs": [],
      "source": [
        "from finrl.main import check_and_make_directories\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance provides stock data, financial news, financial reports, etc. Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** in FinRL-Meta to fetch data via Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h3XJnvrbLp-C",
        "outputId": "43a6df4b-1a4f-4835-a7d3-4f4da695f474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2020-05-18'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from config.py, TRAIN_START_DATE is a string\n",
        "TRAIN_START_DATE\n",
        "# from config.py, TRAIN_END_DATE is a string\n",
        "TRAIN_END_DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2009-01-01'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TRAIN_START_DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2023-03-23'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TRADE_END_DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "9012549f-ac6c-48d3-9254-b162a53930a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (104801, 8)\n"
          ]
        }
      ],
      "source": [
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TRADE_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "c39fd69d-4815-416d-8bef-54dc7c6abcbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
          ]
        }
      ],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "5f69723b-2a5d-4d64-87c5-3a6d3abecd3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(104801, 8)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "7adbffad-04bf-4b83-d47e-6b25cb56efa6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.080002</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>43.832626</td>\n",
              "      <td>6547900</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>18.570000</td>\n",
              "      <td>19.520000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>15.365316</td>\n",
              "      <td>10955700</td>\n",
              "      <td>AXP</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>42.799999</td>\n",
              "      <td>45.560001</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>33.941093</td>\n",
              "      <td>7010200</td>\n",
              "      <td>BA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>46.980000</td>\n",
              "      <td>44.709999</td>\n",
              "      <td>31.579325</td>\n",
              "      <td>7117200</td>\n",
              "      <td>CAT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2009-01-02   3.067143   3.251429   3.041429   2.758535  746015200  AAPL   \n",
              "1  2009-01-02  58.590000  59.080002  57.750000  43.832626    6547900  AMGN   \n",
              "2  2009-01-02  18.570000  19.520000  18.400000  15.365316   10955700   AXP   \n",
              "3  2009-01-02  42.799999  45.560001  42.779999  33.941093    7010200    BA   \n",
              "4  2009-01-02  44.910000  46.980000  44.709999  31.579325    7117200   CAT   \n",
              "\n",
              "   day  \n",
              "0    4  \n",
              "1    4  \n",
              "2    4  \n",
              "3    4  \n",
              "4    4  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic'],ignore_index=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "We need to check for missing data and do feature engineering to convert the data point into a state.\n",
        "* **Adding technical indicators**. In practical trading, various information needs to be taken into account, such as historical prices, current holding shares, technical indicators, etc. Here, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* **Adding turbulence index**. Risk-aversion reflects whether an investor prefers to protect the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the turbulence index that measures extreme fluctuation of asset price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmKP-1ii3RLS",
        "outputId": "da44c66b-ec26-4950-c85c-2bd1aa80d8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3579, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = INDICATORS,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Kixon2tR3RLT"
      },
      "outputs": [],
      "source": [
        "list_ticker = processed[\"tic\"].unique().tolist()\n",
        "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
        "combination = list(itertools.product(list_date,list_ticker))\n",
        "\n",
        "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
        "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "processed_full = processed_full.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "grvhGJJII3Xn",
        "outputId": "935e319f-b7d8-4ed5-971d-05ef8c92e78b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>746015200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.080002</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>43.832626</td>\n",
              "      <td>6547900.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.832626</td>\n",
              "      <td>43.832626</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AXP</td>\n",
              "      <td>18.570000</td>\n",
              "      <td>19.520000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>15.365316</td>\n",
              "      <td>10955700.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>15.365316</td>\n",
              "      <td>15.365316</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>BA</td>\n",
              "      <td>42.799999</td>\n",
              "      <td>45.560001</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>33.941093</td>\n",
              "      <td>7010200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>33.941093</td>\n",
              "      <td>33.941093</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CAT</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>46.980000</td>\n",
              "      <td>44.709999</td>\n",
              "      <td>31.579325</td>\n",
              "      <td>7117200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>31.579325</td>\n",
              "      <td>31.579325</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CRM</td>\n",
              "      <td>8.025000</td>\n",
              "      <td>8.550000</td>\n",
              "      <td>7.912500</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>4069200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CSCO</td>\n",
              "      <td>16.410000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.250000</td>\n",
              "      <td>11.948336</td>\n",
              "      <td>40980600.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>11.948336</td>\n",
              "      <td>11.948336</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CVX</td>\n",
              "      <td>74.230003</td>\n",
              "      <td>77.300003</td>\n",
              "      <td>73.580002</td>\n",
              "      <td>43.677181</td>\n",
              "      <td>13695900.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.677181</td>\n",
              "      <td>43.677181</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>DIS</td>\n",
              "      <td>22.760000</td>\n",
              "      <td>24.030001</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>9796600.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>GS</td>\n",
              "      <td>84.019997</td>\n",
              "      <td>87.620003</td>\n",
              "      <td>82.190002</td>\n",
              "      <td>69.251762</td>\n",
              "      <td>14088500.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.98139</td>\n",
              "      <td>2.652102</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>69.251762</td>\n",
              "      <td>69.251762</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic       open       high        low      close       volume  \\\n",
              "0  2009-01-02  AAPL   3.067143   3.251429   3.041429   2.758535  746015200.0   \n",
              "1  2009-01-02  AMGN  58.590000  59.080002  57.750000  43.832626    6547900.0   \n",
              "2  2009-01-02   AXP  18.570000  19.520000  18.400000  15.365316   10955700.0   \n",
              "3  2009-01-02    BA  42.799999  45.560001  42.779999  33.941093    7010200.0   \n",
              "4  2009-01-02   CAT  44.910000  46.980000  44.709999  31.579325    7117200.0   \n",
              "5  2009-01-02   CRM   8.025000   8.550000   7.912500   8.505000    4069200.0   \n",
              "6  2009-01-02  CSCO  16.410000  17.000000  16.250000  11.948336   40980600.0   \n",
              "7  2009-01-02   CVX  74.230003  77.300003  73.580002  43.677181   13695900.0   \n",
              "8  2009-01-02   DIS  22.760000  24.030001  22.500000  20.597494    9796600.0   \n",
              "9  2009-01-02    GS  84.019997  87.620003  82.190002  69.251762   14088500.0   \n",
              "\n",
              "   day  macd  boll_ub   boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
              "0  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0      2.758535   \n",
              "1  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     43.832626   \n",
              "2  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     15.365316   \n",
              "3  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     33.941093   \n",
              "4  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     31.579325   \n",
              "5  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0      8.505000   \n",
              "6  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     11.948336   \n",
              "7  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     43.677181   \n",
              "8  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     20.597494   \n",
              "9  4.0   0.0  2.98139  2.652102   100.0  66.666667  100.0     69.251762   \n",
              "\n",
              "   close_60_sma        vix  turbulence  \n",
              "0      2.758535  39.189999         0.0  \n",
              "1     43.832626  39.189999         0.0  \n",
              "2     15.365316  39.189999         0.0  \n",
              "3     33.941093  39.189999         0.0  \n",
              "4     31.579325  39.189999         0.0  \n",
              "5      8.505000  39.189999         0.0  \n",
              "6     11.948336  39.189999         0.0  \n",
              "7     43.677181  39.189999         0.0  \n",
              "8     20.597494  39.189999         0.0  \n",
              "9     69.251762  39.189999         0.0  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5vdORQ384Qx-"
      },
      "outputs": [],
      "source": [
        "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3579"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(len(mvo_df)/29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Build A Market Environment in OpenAI Gym-style\n",
        "The training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
        "\n",
        "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TOhcryx44bb"
      },
      "source": [
        "## Data Split\n",
        "We split the data into training set and testing set as follows:\n",
        "\n",
        "Training data period: 2009-01-01 to 2020-07-01\n",
        "\n",
        "Trading data period: 2020-07-01 to 2021-10-31\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qaVGjLtgbI",
        "outputId": "99d9a9eb-68ca-4e0b-f29a-16aeefe05693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82998\n",
            "20793\n"
          ]
        }
      ],
      "source": [
        "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
        "print(len(train))\n",
        "print(len(trade))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "p52zNCOhTtLR",
        "outputId": "22263b87-b851-4d0d-a584-8572bca8ff0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>UNH</td>\n",
              "      <td>292.410004</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>290.720001</td>\n",
              "      <td>278.924530</td>\n",
              "      <td>12182800.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.160590</td>\n",
              "      <td>285.177012</td>\n",
              "      <td>264.528524</td>\n",
              "      <td>53.716935</td>\n",
              "      <td>79.362342</td>\n",
              "      <td>19.780788</td>\n",
              "      <td>268.314394</td>\n",
              "      <td>255.255440</td>\n",
              "      <td>31.889999</td>\n",
              "      <td>35.410115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>V</td>\n",
              "      <td>179.979996</td>\n",
              "      <td>184.139999</td>\n",
              "      <td>178.869995</td>\n",
              "      <td>180.102722</td>\n",
              "      <td>10785900.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.517954</td>\n",
              "      <td>186.313233</td>\n",
              "      <td>157.702491</td>\n",
              "      <td>53.034245</td>\n",
              "      <td>99.128471</td>\n",
              "      <td>3.903157</td>\n",
              "      <td>169.547555</td>\n",
              "      <td>168.528678</td>\n",
              "      <td>31.889999</td>\n",
              "      <td>35.410115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>VZ</td>\n",
              "      <td>54.630001</td>\n",
              "      <td>54.759998</td>\n",
              "      <td>54.209999</td>\n",
              "      <td>47.802036</td>\n",
              "      <td>10174000.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.226676</td>\n",
              "      <td>51.578623</td>\n",
              "      <td>47.485448</td>\n",
              "      <td>46.826959</td>\n",
              "      <td>-165.232343</td>\n",
              "      <td>31.385117</td>\n",
              "      <td>49.595334</td>\n",
              "      <td>48.362976</td>\n",
              "      <td>31.889999</td>\n",
              "      <td>35.410115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>WBA</td>\n",
              "      <td>38.310001</td>\n",
              "      <td>38.480000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>33.706387</td>\n",
              "      <td>17309300.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.254166</td>\n",
              "      <td>40.409377</td>\n",
              "      <td>33.426909</td>\n",
              "      <td>40.887181</td>\n",
              "      <td>-199.332905</td>\n",
              "      <td>39.816185</td>\n",
              "      <td>37.336546</td>\n",
              "      <td>39.112129</td>\n",
              "      <td>31.889999</td>\n",
              "      <td>35.410115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>WMT</td>\n",
              "      <td>123.470001</td>\n",
              "      <td>125.940002</td>\n",
              "      <td>123.089996</td>\n",
              "      <td>120.613297</td>\n",
              "      <td>10590000.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.498669</td>\n",
              "      <td>125.450063</td>\n",
              "      <td>114.250607</td>\n",
              "      <td>54.354140</td>\n",
              "      <td>-8.839857</td>\n",
              "      <td>0.410854</td>\n",
              "      <td>119.906011</td>\n",
              "      <td>114.327323</td>\n",
              "      <td>31.889999</td>\n",
              "      <td>35.410115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  tic        open        high         low       close  \\\n",
              "2861  2020-05-15  UNH  292.410004  300.000000  290.720001  278.924530   \n",
              "2861  2020-05-15    V  179.979996  184.139999  178.869995  180.102722   \n",
              "2861  2020-05-15   VZ   54.630001   54.759998   54.209999   47.802036   \n",
              "2861  2020-05-15  WBA   38.310001   38.480000   37.500000   33.706387   \n",
              "2861  2020-05-15  WMT  123.470001  125.940002  123.089996  120.613297   \n",
              "\n",
              "          volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
              "2861  12182800.0  4.0  5.160590  285.177012  264.528524  53.716935   \n",
              "2861  10785900.0  4.0  3.517954  186.313233  157.702491  53.034245   \n",
              "2861  10174000.0  4.0 -0.226676   51.578623   47.485448  46.826959   \n",
              "2861  17309300.0  4.0 -1.254166   40.409377   33.426909  40.887181   \n",
              "2861  10590000.0  4.0  0.498669  125.450063  114.250607  54.354140   \n",
              "\n",
              "          cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
              "2861   79.362342  19.780788    268.314394    255.255440  31.889999   35.410115  \n",
              "2861   99.128471   3.903157    169.547555    168.528678  31.889999   35.410115  \n",
              "2861 -165.232343  31.385117     49.595334     48.362976  31.889999   35.410115  \n",
              "2861 -199.332905  39.816185     37.336546     39.112129  31.889999   35.410115  \n",
              "2861   -8.839857   0.410854    119.906011    114.327323  31.889999   35.410115  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "k9zU9YaTTvFq",
        "outputId": "f8289fe9-674a-4456-aaea-9d021ddbb5a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>78.292503</td>\n",
              "      <td>79.125000</td>\n",
              "      <td>77.580002</td>\n",
              "      <td>77.414001</td>\n",
              "      <td>135178400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.628294</td>\n",
              "      <td>79.787533</td>\n",
              "      <td>65.136369</td>\n",
              "      <td>58.018337</td>\n",
              "      <td>128.081424</td>\n",
              "      <td>34.622794</td>\n",
              "      <td>70.754270</td>\n",
              "      <td>67.761639</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>243.660004</td>\n",
              "      <td>244.389999</td>\n",
              "      <td>231.800003</td>\n",
              "      <td>214.447021</td>\n",
              "      <td>5631400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.237348</td>\n",
              "      <td>222.581990</td>\n",
              "      <td>208.394304</td>\n",
              "      <td>53.511971</td>\n",
              "      <td>57.692987</td>\n",
              "      <td>31.990941</td>\n",
              "      <td>211.469554</td>\n",
              "      <td>198.274533</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>AXP</td>\n",
              "      <td>86.720001</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>85.919998</td>\n",
              "      <td>85.229942</td>\n",
              "      <td>7781700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.096790</td>\n",
              "      <td>90.298287</td>\n",
              "      <td>74.832442</td>\n",
              "      <td>48.085958</td>\n",
              "      <td>33.068757</td>\n",
              "      <td>0.620002</td>\n",
              "      <td>83.116470</td>\n",
              "      <td>87.170146</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>BA</td>\n",
              "      <td>126.180000</td>\n",
              "      <td>136.199997</td>\n",
              "      <td>125.800003</td>\n",
              "      <td>135.440002</td>\n",
              "      <td>43781800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-7.191083</td>\n",
              "      <td>142.655067</td>\n",
              "      <td>117.923934</td>\n",
              "      <td>42.534953</td>\n",
              "      <td>-29.016130</td>\n",
              "      <td>4.926572</td>\n",
              "      <td>135.367000</td>\n",
              "      <td>164.372832</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>CAT</td>\n",
              "      <td>112.220001</td>\n",
              "      <td>115.660004</td>\n",
              "      <td>112.010002</td>\n",
              "      <td>108.081749</td>\n",
              "      <td>5603500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.169124</td>\n",
              "      <td>112.040902</td>\n",
              "      <td>96.223666</td>\n",
              "      <td>50.214111</td>\n",
              "      <td>17.694228</td>\n",
              "      <td>3.519003</td>\n",
              "      <td>106.144327</td>\n",
              "      <td>104.895563</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic        open        high         low       close  \\\n",
              "0  2020-05-18  AAPL   78.292503   79.125000   77.580002   77.414001   \n",
              "0  2020-05-18  AMGN  243.660004  244.389999  231.800003  214.447021   \n",
              "0  2020-05-18   AXP   86.720001   89.000000   85.919998   85.229942   \n",
              "0  2020-05-18    BA  126.180000  136.199997  125.800003  135.440002   \n",
              "0  2020-05-18   CAT  112.220001  115.660004  112.010002  108.081749   \n",
              "\n",
              "        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
              "0  135178400.0  0.0  2.628294   79.787533   65.136369  58.018337  128.081424   \n",
              "0    5631400.0  0.0  4.237348  222.581990  208.394304  53.511971   57.692987   \n",
              "0    7781700.0  0.0 -1.096790   90.298287   74.832442  48.085958   33.068757   \n",
              "0   43781800.0  0.0 -7.191083  142.655067  117.923934  42.534953  -29.016130   \n",
              "0    5603500.0  0.0 -1.169124  112.040902   96.223666  50.214111   17.694228   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
              "0  34.622794     70.754270     67.761639  29.299999   68.142733  \n",
              "0  31.990941    211.469554    198.274533  29.299999   68.142733  \n",
              "0   0.620002     83.116470     87.170146  29.299999   68.142733  \n",
              "0   4.926572    135.367000    164.372832  29.299999   68.142733  \n",
              "0   3.519003    106.144327    104.895563  29.299999   68.142733  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trade.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYN573SOHhxG",
        "outputId": "e8e3426a-3f41-4153-c5ff-80b9a997c9ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INDICATORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "0d415071-8d51-42f9-b141-f2122e272da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}\n",
        "\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64EoqOrQjiVf"
      },
      "source": [
        "## Environment for Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwSvvPjutpqS",
        "outputId": "78c63dfc-e3c8-4d7a-f807-4ce7058d5384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Train DRL Agents\n",
        "* The DRL algorithms are from **Stable Baselines 3**. Users are also encouraged to try **ElegantRL** and **Ray RLlib**.\n",
        "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "364PsqckttcQ"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "if_using_a2c = True\n",
        "if_using_ddpg = True\n",
        "if_using_ppo = True\n",
        "if_using_td3 = True\n",
        "if_using_sac = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDmqOyF9h1iz"
      },
      "source": [
        "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uijiWgkuh1jB"
      },
      "source": [
        "### Agent 1: A2C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUCnkn-HIbmj",
        "outputId": "8be899ae-c772-46fd-e613-92dacfa9ed4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-24 11:37:42.585920: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-24 11:37:43.334306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/acraf/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-03-24 11:37:43.334386: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/acraf/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-03-24 11:37:43.334395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to results/a2c\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "if if_using_a2c:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/a2c'\n",
        "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_a2c.set_logger(new_logger_a2c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GVpkWGqH4-D",
        "outputId": "4772e493-7857-4ea6-e091-a8fbc665f06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -8.61     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -0.466    |\n",
            "|    reward             | 0.1698805 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.297     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 115       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -133      |\n",
            "|    reward             | -1.892637 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.411     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -250      |\n",
            "|    reward             | 7.0539045 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 35.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 119      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -90.1    |\n",
            "|    reward             | 4.019531 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 5.55     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 120       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 428       |\n",
            "|    reward             | -8.846421 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 160       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 121        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.446      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 179        |\n",
            "|    reward             | 0.05545537 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 18.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 121       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.103    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 27.9      |\n",
            "|    reward             | 0.2431213 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.22      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 120       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 81.7      |\n",
            "|    reward             | 0.8643641 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.97      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 119        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -188       |\n",
            "|    reward             | -3.0684412 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 21.4       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 119          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 41           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.3        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -85          |\n",
            "|    reward             | -0.093029626 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 4.99         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 129        |\n",
            "|    reward             | 0.28676254 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 14.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -2.23      |\n",
            "|    reward             | -1.9321877 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.718      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 119       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.0596    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 33.8      |\n",
            "|    reward             | 1.6597245 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.781     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 119        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 58         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -1.19e-06  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -60.8      |\n",
            "|    reward             | -1.7408854 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.43       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -218      |\n",
            "|    reward             | -3.530688 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 30.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 67         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 215        |\n",
            "|    reward             | 0.73009276 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 29.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -405      |\n",
            "|    reward             | 5.0756173 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 111       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 75         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 33.9       |\n",
            "|    reward             | 0.18550892 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.02       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 16.6       |\n",
            "|    reward             | -0.3507513 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.336      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -0.161     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -188       |\n",
            "|    reward             | -1.1252879 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 37.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -0.00122  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -122      |\n",
            "|    reward             | 1.2518585 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 13.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 92         |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 169        |\n",
            "|    reward             | 0.77185106 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 18.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -5.82     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 506       |\n",
            "|    reward             | -2.533733 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 211       |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 118          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 101          |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.4        |\n",
            "|    explained_variance | 0.036        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | -70.1        |\n",
            "|    reward             | -0.007342006 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 4.91         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 105        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | 86.3       |\n",
            "|    reward             | 0.16497861 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 8.73       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | -21.4     |\n",
            "|    reward             | 0.3528206 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.6       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 113        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 154        |\n",
            "|    reward             | -1.2676566 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 15.5       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 118         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | 278         |\n",
            "|    reward             | -0.26180023 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 53.6        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | -2.49     |\n",
            "|    reward             | 1.8244436 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.18      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 126        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | -170       |\n",
            "|    reward             | -1.9966532 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 19.1       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 118          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 130          |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.3        |\n",
            "|    explained_variance | 0.138        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | 173          |\n",
            "|    reward             | -0.067771986 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 20.2         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 134         |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | -9.35       |\n",
            "|    reward             | -0.25325593 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 7.86        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 139         |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | -166        |\n",
            "|    reward             | -0.59098536 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 18.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 143       |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 108       |\n",
            "|    reward             | 0.7448243 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 19.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | -79.5     |\n",
            "|    reward             | 0.8950535 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.66      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 118      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 151      |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -245     |\n",
            "|    reward             | 2.146726 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 37.1     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 156        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | -159       |\n",
            "|    reward             | 0.44414777 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 17.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 160       |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 96.8      |\n",
            "|    reward             | 1.1632373 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.64      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 118      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 164      |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -284     |\n",
            "|    reward             | 6.03516  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 131      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 168       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -1.16e+03 |\n",
            "|    reward             | 17.020277 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 872       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 172        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 26.6       |\n",
            "|    reward             | -0.6644697 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.607      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 177        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | -153       |\n",
            "|    reward             | -2.5927174 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 24.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 181       |\n",
            "|    total_timesteps    | 21500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 367       |\n",
            "|    reward             | 1.9702063 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 114       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 185       |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.00279  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | -138      |\n",
            "|    reward             | 0.8299257 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 16.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 189        |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | -1e+03     |\n",
            "|    reward             | -4.3264318 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 619        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 194         |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | -0.00642    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -37.3       |\n",
            "|    reward             | -0.41212013 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.88        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 198        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -0.705     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 42.8       |\n",
            "|    reward             | -0.4138224 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.74       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 202       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -18       |\n",
            "|    reward             | 0.3538054 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 3.32      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 206         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0.01        |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -44.1       |\n",
            "|    reward             | -0.82728356 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 6.34        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 211        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -4.22      |\n",
            "|    reward             | 0.43337694 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.569      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 118      |\n",
            "|    iterations         | 5100     |\n",
            "|    time_elapsed       | 215      |\n",
            "|    total_timesteps    | 25500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | -0.00597 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5099     |\n",
            "|    policy_loss        | -332     |\n",
            "|    reward             | -7.13503 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 76.4     |\n",
            "------------------------------------\n",
            "day: 2861, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4957008.54\n",
            "total_reward: 3957008.54\n",
            "total_cost: 76470.75\n",
            "total_trades: 53243\n",
            "Sharpe: 0.818\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 219        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.113      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | 27.4       |\n",
            "|    reward             | -2.0326376 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.36       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 223       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.133    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 122       |\n",
            "|    reward             | -4.349982 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 31.1      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 228         |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | -62         |\n",
            "|    reward             | -0.23872927 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.58        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 232       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0.0655    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 40        |\n",
            "|    reward             | -2.486433 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.2       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 236       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -22.8     |\n",
            "|    reward             | 6.1801624 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 241       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | 2.22      |\n",
            "|    reward             | 2.5504289 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.56      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 245       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0.0512    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | -196      |\n",
            "|    reward             | 2.8569107 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 24.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 249       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | -105      |\n",
            "|    reward             | 3.8345788 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11.2      |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 118           |\n",
            "|    iterations         | 6000          |\n",
            "|    time_elapsed       | 253           |\n",
            "|    total_timesteps    | 30000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -41.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5999          |\n",
            "|    policy_loss        | 162           |\n",
            "|    reward             | 0.00035196712 |\n",
            "|    std                | 1.02          |\n",
            "|    value_loss         | 15.5          |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 258        |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | -155       |\n",
            "|    reward             | -1.8527038 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 21.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 262        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | 226        |\n",
            "|    reward             | -3.6565976 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 74.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 266       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | 13.6      |\n",
            "|    reward             | -1.559807 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.585     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 6400      |\n",
            "|    time_elapsed       | 271       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0.0536    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6399      |\n",
            "|    policy_loss        | 56        |\n",
            "|    reward             | 1.7049311 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.77      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 275       |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | 17.7      |\n",
            "|    reward             | 1.0019097 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.328     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 279        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -29.8      |\n",
            "|    reward             | -2.7446818 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 41.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 283       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -172      |\n",
            "|    reward             | 1.8598418 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 17.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 287       |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.000259 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 823       |\n",
            "|    reward             | 20.199078 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 556       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 118        |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 292        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -13.1      |\n",
            "|    reward             | -3.1299593 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.593      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 296       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0.00565   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -208      |\n",
            "|    reward             | -8.432923 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 33.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 7100      |\n",
            "|    time_elapsed       | 300       |\n",
            "|    total_timesteps    | 35500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7099      |\n",
            "|    policy_loss        | -90.7     |\n",
            "|    reward             | 2.4294653 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 4.2       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 304       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7199      |\n",
            "|    policy_loss        | -248      |\n",
            "|    reward             | -2.125683 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 54        |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 118         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 309         |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | -360        |\n",
            "|    reward             | -0.64561105 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 74.7        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 7400      |\n",
            "|    time_elapsed       | 313       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -0.000859 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7399      |\n",
            "|    policy_loss        | -129      |\n",
            "|    reward             | -4.155971 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 46.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 118       |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 317       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -0.00762  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | -13       |\n",
            "|    reward             | 1.8730091 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.642     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 117        |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 322        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 48.3       |\n",
            "|    reward             | 0.37385413 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.44       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 117       |\n",
            "|    iterations         | 7700      |\n",
            "|    time_elapsed       | 326       |\n",
            "|    total_timesteps    | 38500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7699      |\n",
            "|    policy_loss        | 77.3      |\n",
            "|    reward             | 2.4700248 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.45      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 117       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 332       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | -345      |\n",
            "|    reward             | 1.9907112 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 97        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 337       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -553      |\n",
            "|    reward             | -1.363425 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 393       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 342       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | 60.3      |\n",
            "|    reward             | 5.9156723 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 15.1      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 116      |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 347      |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | 4.93     |\n",
            "|    reward             | 0.645735 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.475    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 8200      |\n",
            "|    time_elapsed       | 352       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -0.000165 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8199      |\n",
            "|    policy_loss        | 84.3      |\n",
            "|    reward             | 3.734268  |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 5.16      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 115        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 357        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | -92.4      |\n",
            "|    reward             | 0.01731882 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 7.87       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 115       |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 362       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | 0.28      |\n",
            "|    reward             | 1.3192502 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.72      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 366       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | 96.1      |\n",
            "|    reward             | -4.065712 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 14.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 370       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -4.58e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | -23.8     |\n",
            "|    reward             | 2.1956427 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 5.76      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 115          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 375          |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.6        |\n",
            "|    explained_variance | -0.00413     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | 12           |\n",
            "|    reward             | -0.033781745 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 1.16         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 115        |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 380        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0.00746    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | 38.6       |\n",
            "|    reward             | -0.7408246 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 3.48       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 115        |\n",
            "|    iterations         | 8900       |\n",
            "|    time_elapsed       | 386        |\n",
            "|    total_timesteps    | 44500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8899       |\n",
            "|    policy_loss        | -128       |\n",
            "|    reward             | -3.9589574 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 13         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 114        |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 393        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 137        |\n",
            "|    reward             | -1.1635419 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 13.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 398       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | -745      |\n",
            "|    reward             | 4.506733  |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 495       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 403       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -0.00909  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | -27.3     |\n",
            "|    reward             | 3.9277873 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.91      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 113       |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 408       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | -78.9     |\n",
            "|    reward             | 2.8041174 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 5.45      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 113        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 412        |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | 214        |\n",
            "|    reward             | -0.1292743 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 37.6       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 417      |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | 359      |\n",
            "|    reward             | 4.2261   |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 98.6     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 421      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | 166      |\n",
            "|    reward             | 1.404462 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 17.1     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 113        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 425        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.000208  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 152        |\n",
            "|    reward             | -2.2594159 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 18.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 113       |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 430       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.00128  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9799      |\n",
            "|    policy_loss        | 211       |\n",
            "|    reward             | -1.292021 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 35.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 113       |\n",
            "|    iterations         | 9900      |\n",
            "|    time_elapsed       | 435       |\n",
            "|    total_timesteps    | 49500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9899      |\n",
            "|    policy_loss        | -219      |\n",
            "|    reward             | 0.2865653 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 25.2      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 113       |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 440       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | -23.3     |\n",
            "|    reward             | 0.9147288 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.31      |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                             tb_log_name='a2c',\n",
        "                             total_timesteps=50000) if if_using_a2c else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRiOtrywfAo1"
      },
      "source": [
        "### Agent 2: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2YadjfnLwgt",
        "outputId": "2daa7acb-8985-4122-84ca-74537316bef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/ddpg\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg = agent.get_model(\"ddpg\")\n",
        "\n",
        "if if_using_ddpg:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ddpg'\n",
        "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ddpg.set_logger(new_logger_ddpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDa78rqfO_a",
        "outputId": "5ef7cb2f-7665-4266-8fab-2f9534de43cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 2861, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4258845.95\n",
            "total_reward: 3258845.95\n",
            "total_cost: 5100.02\n",
            "total_trades: 47314\n",
            "Sharpe: 0.720\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 54       |\n",
            "|    time_elapsed    | 209      |\n",
            "|    total_timesteps | 11448    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 42       |\n",
            "|    critic_loss     | 190      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8586     |\n",
            "|    reward          | 5.439996 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 51       |\n",
            "|    time_elapsed    | 443      |\n",
            "|    total_timesteps | 22896    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.5     |\n",
            "|    critic_loss     | 7.56     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 20034    |\n",
            "|    reward          | 5.439996 |\n",
            "---------------------------------\n",
            "day: 2861, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4734732.59\n",
            "total_reward: 3734732.59\n",
            "total_cost: 999.00\n",
            "total_trades: 40024\n",
            "Sharpe: 0.810\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 48       |\n",
            "|    time_elapsed    | 709      |\n",
            "|    total_timesteps | 34344    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.849    |\n",
            "|    critic_loss     | 4.44     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31482    |\n",
            "|    reward          | 5.439996 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 47       |\n",
            "|    time_elapsed    | 957      |\n",
            "|    total_timesteps | 45792    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.35    |\n",
            "|    critic_loss     | 3.29     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42930    |\n",
            "|    reward          | 5.439996 |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=50000) if if_using_ddpg else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gDkU-j-fCmZ"
      },
      "source": [
        "### Agent 3: PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5D5PFUhMzSV",
        "outputId": "54d861fd-b7d5-47f1-e0d6-fe8301a6fee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to results/ppo\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "\n",
        "if if_using_ppo:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ppo'\n",
        "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ppo.set_logger(new_logger_ppo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt8eIQKYM4G3",
        "outputId": "52802a60-c084-4d89-96cf-b645177f7161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 133        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 15         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.39777517 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 109         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017784588 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0247     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 10.3        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    reward               | 0.71577746  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 21.4        |\n",
            "-----------------------------------------\n",
            "day: 2861, episode: 40\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2872853.46\n",
            "total_reward: 1872853.46\n",
            "total_cost: 322518.98\n",
            "total_trades: 78767\n",
            "Sharpe: 0.557\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015489596 |\n",
            "|    clip_fraction        | 0.202       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.000951   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 47.1        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    reward               | 0.6948692   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 66.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 101         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012521436 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.000196    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 248         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    reward               | -3.7860148  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 197         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 98          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015099955 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.000274    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 12.5        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    reward               | -0.34486103 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 29.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 105         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019758835 |\n",
            "|    clip_fraction        | 0.215       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | -0.000558   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 37.8        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    reward               | -1.3351805  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 54.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 106         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 134         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012509642 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.5       |\n",
            "|    explained_variance   | -0.00299    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 35.7        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    reward               | -1.2311652  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 175         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 107         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 152         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013767306 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.5       |\n",
            "|    explained_variance   | -0.0152     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 46.5        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    reward               | 1.7279832   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 91          |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 107        |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 170        |\n",
            "|    total_timesteps      | 18432      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01789745 |\n",
            "|    clip_fraction        | 0.179      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.6      |\n",
            "|    explained_variance   | 0.00651    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 8.51       |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.0176    |\n",
            "|    reward               | -0.8670094 |\n",
            "|    std                  | 1.02       |\n",
            "|    value_loss           | 19.3       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 108         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 189         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023455724 |\n",
            "|    clip_fraction        | 0.203       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.6       |\n",
            "|    explained_variance   | 0.00751     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 69.2        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    reward               | 0.21127681  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 106         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 108         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 207         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022017734 |\n",
            "|    clip_fraction        | 0.265       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.7       |\n",
            "|    explained_variance   | -0.00321    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 50          |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    reward               | 14.281492   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 84.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 109         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 224         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028350312 |\n",
            "|    clip_fraction        | 0.266       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.00465     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 21.1        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0153     |\n",
            "|    reward               | -3.1284058  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 39.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 110         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 240         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017050235 |\n",
            "|    clip_fraction        | 0.182       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | -0.000984   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.3        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    reward               | -1.3905007  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 132         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 111         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 256         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024084155 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.9       |\n",
            "|    explained_variance   | -0.00732    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 75.7        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    reward               | -0.73935586 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 186         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 112         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 273         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019321341 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.9       |\n",
            "|    explained_variance   | 0.00293     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 68.7        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.014      |\n",
            "|    reward               | 0.27777928  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 113         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 289         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026167654 |\n",
            "|    clip_fraction        | 0.236       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | -0.0243     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 11.2        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0175     |\n",
            "|    reward               | -0.86246955 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 25.5        |\n",
            "-----------------------------------------\n",
            "day: 2861, episode: 50\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3852427.93\n",
            "total_reward: 2852427.93\n",
            "total_cost: 300751.36\n",
            "total_trades: 76128\n",
            "Sharpe: 0.701\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 114        |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 303        |\n",
            "|    total_timesteps      | 34816      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01566808 |\n",
            "|    clip_fraction        | 0.19       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42        |\n",
            "|    explained_variance   | 0.00735    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 87.4       |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.0198    |\n",
            "|    reward               | -2.0225215 |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 220        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 115         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 318         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018904047 |\n",
            "|    clip_fraction        | 0.242       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | 0.0102      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 76.7        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    reward               | 9.325589    |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 197         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 115         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 335         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015432337 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | 0.00697     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 19.1        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    reward               | -0.70961404 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 52.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 116         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 352         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012315213 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | -0.0191     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 22.7        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0173     |\n",
            "|    reward               | 2.2666337   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 132         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 116         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 368         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021585813 |\n",
            "|    clip_fraction        | 0.184       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | -0.0036     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 180         |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00638    |\n",
            "|    reward               | -0.17132007 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 233         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 116         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 385         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026940027 |\n",
            "|    clip_fraction        | 0.232       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | 0.00293     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 86.2        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00934    |\n",
            "|    reward               | 1.3008255   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 182         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 117         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 402         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028425507 |\n",
            "|    clip_fraction        | 0.331       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | -0.0368     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 12.4        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00932    |\n",
            "|    reward               | -1.2982122  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 25.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 117          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.021172918  |\n",
            "|    clip_fraction        | 0.233        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.2        |\n",
            "|    explained_variance   | 0.0133       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 68           |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.0159      |\n",
            "|    reward               | -0.004815275 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 217          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 117         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 435         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030571649 |\n",
            "|    clip_fraction        | 0.242       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.00811     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 202         |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    reward               | 0.36177906  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 344         |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=50000) if if_using_ppo else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zpv4S0-fDBv"
      },
      "source": [
        "### Agent 4: TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSAHhV4Xc-bh",
        "outputId": "4a18e366-4c60-4262-cebd-9f291072fdb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/td3\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 100, \n",
        "              \"buffer_size\": 1000000, \n",
        "              \"learning_rate\": 0.001}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
        "\n",
        "if if_using_td3:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/td3'\n",
        "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_td3.set_logger(new_logger_td3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSRxNYAxdKpU",
        "outputId": "5891ff4e-c36e-4ab7-97e7-75ce12630eeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 2861, episode: 60\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4316640.36\n",
            "total_reward: 3316640.36\n",
            "total_cost: 999.00\n",
            "total_trades: 42915\n",
            "Sharpe: 0.787\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 59       |\n",
            "|    time_elapsed    | 191      |\n",
            "|    total_timesteps | 11448    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.2    |\n",
            "|    critic_loss     | 230      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8586     |\n",
            "|    reward          | 2.440315 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 55       |\n",
            "|    time_elapsed    | 413      |\n",
            "|    total_timesteps | 22896    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.11    |\n",
            "|    critic_loss     | 61       |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 20034    |\n",
            "|    reward          | 2.440315 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 53       |\n",
            "|    time_elapsed    | 636      |\n",
            "|    total_timesteps | 34344    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.769   |\n",
            "|    critic_loss     | 19.3     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31482    |\n",
            "|    reward          | 2.440315 |\n",
            "---------------------------------\n",
            "day: 2861, episode: 70\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4316640.36\n",
            "total_reward: 3316640.36\n",
            "total_cost: 999.00\n",
            "total_trades: 42915\n",
            "Sharpe: 0.787\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 53       |\n",
            "|    time_elapsed    | 861      |\n",
            "|    total_timesteps | 45792    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.4      |\n",
            "|    critic_loss     | 11.1     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 42930    |\n",
            "|    reward          | 2.440315 |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=50000) if if_using_td3 else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr49PotrfG01"
      },
      "source": [
        "### Agent 5: SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwOhVjqRkCdM",
        "outputId": "bf6bfbf2-251a-4c76-ac72-1730dbc71eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to results/sac\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "\n",
        "if if_using_sac:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/sac'\n",
        "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_sac.set_logger(new_logger_sac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8RSdKCckJyH",
        "outputId": "313f9f27-3b80-4b00-d2ce-6bc5ea86ca27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 43       |\n",
            "|    time_elapsed    | 265      |\n",
            "|    total_timesteps | 11448    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 617      |\n",
            "|    critic_loss     | 74.3     |\n",
            "|    ent_coef        | 0.136    |\n",
            "|    ent_coef_loss   | -86.6    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 11347    |\n",
            "|    reward          | 2.590422 |\n",
            "---------------------------------\n",
            "day: 2861, episode: 80\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5746610.69\n",
            "total_reward: 4746610.69\n",
            "total_cost: 152318.78\n",
            "total_trades: 69192\n",
            "Sharpe: 0.850\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 42        |\n",
            "|    time_elapsed    | 536       |\n",
            "|    total_timesteps | 22896     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 298       |\n",
            "|    critic_loss     | 40.4      |\n",
            "|    ent_coef        | 0.0432    |\n",
            "|    ent_coef_loss   | -132      |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 22795     |\n",
            "|    reward          | 0.2890321 |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 42       |\n",
            "|    time_elapsed    | 804      |\n",
            "|    total_timesteps | 34344    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 151      |\n",
            "|    critic_loss     | 13.6     |\n",
            "|    ent_coef        | 0.0142   |\n",
            "|    ent_coef_loss   | -126     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 34243    |\n",
            "|    reward          | 2.514646 |\n",
            "---------------------------------\n",
            "day: 2861, episode: 90\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4271205.76\n",
            "total_reward: 3271205.76\n",
            "total_cost: 3598.75\n",
            "total_trades: 51302\n",
            "Sharpe: 0.722\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 42        |\n",
            "|    time_elapsed    | 1075      |\n",
            "|    total_timesteps | 45792     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 73        |\n",
            "|    critic_loss     | 10.7      |\n",
            "|    ent_coef        | 0.00489   |\n",
            "|    ent_coef_loss   | -71.2     |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 45691     |\n",
            "|    reward          | 2.6899529 |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=50000) if if_using_sac else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2wZgkQXh1jE"
      },
      "source": [
        "## In-sample Performance\n",
        "\n",
        "Assume that the initial capital is $1,000,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEv5KGC8h1jE"
      },
      "source": [
        "### Set turbulence threshold\n",
        "Set the turbulence threshold to be greater than the maximum of insample turbulence data. If current turbulence index is greater than the threshold, then we assume that the current market is volatile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "efwBi84ch1jE"
      },
      "outputs": [],
      "source": [
        "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
        "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHZMBpSqh1jG",
        "outputId": "ff203a99-ab49-4970-810a-645f30fab21c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2862.000000\n",
              "mean       18.699046\n",
              "std         8.440450\n",
              "min         9.140000\n",
              "25%        13.310000\n",
              "50%        16.075000\n",
              "75%        21.087500\n",
              "max        82.690002\n",
              "Name: vix, dtype: float64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.vix.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDkszkMloRWT",
        "outputId": "3fae2054-33b6-40da-f057-78da8dda3077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57.49700183105472"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.vix.quantile(0.996)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL7hs7svnNWT",
        "outputId": "7ff675ad-25b8-4d26-ef32-f58237d20b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2862.000000\n",
              "mean       34.582518\n",
              "std        43.997254\n",
              "min         0.000000\n",
              "25%        14.908499\n",
              "50%        24.046682\n",
              "75%        39.166076\n",
              "max       652.507418\n",
              "Name: turbulence, dtype: float64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.turbulence.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N78hfHckoqJ9",
        "outputId": "f5e548c1-6891-4209-cbff-0e25b54fc8aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "276.97107299845146"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.turbulence.quantile(0.996)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5mmgQF_h1jQ"
      },
      "source": [
        "### Trading (Out-of-sample Performance)\n",
        "\n",
        "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
        "\n",
        "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cIqoV0GSI52v"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
        "#env_trade, obs_trade = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "W_XNgGsBMeVw",
        "outputId": "45a92b16-4907-421b-bf48-8b0ff4bff45b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>78.292503</td>\n",
              "      <td>79.125000</td>\n",
              "      <td>77.580002</td>\n",
              "      <td>77.414001</td>\n",
              "      <td>135178400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.628294</td>\n",
              "      <td>79.787533</td>\n",
              "      <td>65.136369</td>\n",
              "      <td>58.018337</td>\n",
              "      <td>128.081424</td>\n",
              "      <td>34.622794</td>\n",
              "      <td>70.754270</td>\n",
              "      <td>67.761639</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>243.660004</td>\n",
              "      <td>244.389999</td>\n",
              "      <td>231.800003</td>\n",
              "      <td>214.447021</td>\n",
              "      <td>5631400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.237348</td>\n",
              "      <td>222.581990</td>\n",
              "      <td>208.394304</td>\n",
              "      <td>53.511971</td>\n",
              "      <td>57.692987</td>\n",
              "      <td>31.990941</td>\n",
              "      <td>211.469554</td>\n",
              "      <td>198.274533</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>AXP</td>\n",
              "      <td>86.720001</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>85.919998</td>\n",
              "      <td>85.229942</td>\n",
              "      <td>7781700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.096790</td>\n",
              "      <td>90.298287</td>\n",
              "      <td>74.832442</td>\n",
              "      <td>48.085958</td>\n",
              "      <td>33.068757</td>\n",
              "      <td>0.620002</td>\n",
              "      <td>83.116470</td>\n",
              "      <td>87.170146</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>BA</td>\n",
              "      <td>126.180000</td>\n",
              "      <td>136.199997</td>\n",
              "      <td>125.800003</td>\n",
              "      <td>135.440002</td>\n",
              "      <td>43781800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-7.191083</td>\n",
              "      <td>142.655067</td>\n",
              "      <td>117.923934</td>\n",
              "      <td>42.534953</td>\n",
              "      <td>-29.016130</td>\n",
              "      <td>4.926572</td>\n",
              "      <td>135.367000</td>\n",
              "      <td>164.372832</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-05-18</td>\n",
              "      <td>CAT</td>\n",
              "      <td>112.220001</td>\n",
              "      <td>115.660004</td>\n",
              "      <td>112.010002</td>\n",
              "      <td>108.081749</td>\n",
              "      <td>5603500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.169124</td>\n",
              "      <td>112.040902</td>\n",
              "      <td>96.223666</td>\n",
              "      <td>50.214111</td>\n",
              "      <td>17.694228</td>\n",
              "      <td>3.519003</td>\n",
              "      <td>106.144327</td>\n",
              "      <td>104.895563</td>\n",
              "      <td>29.299999</td>\n",
              "      <td>68.142733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic        open        high         low       close  \\\n",
              "0  2020-05-18  AAPL   78.292503   79.125000   77.580002   77.414001   \n",
              "0  2020-05-18  AMGN  243.660004  244.389999  231.800003  214.447021   \n",
              "0  2020-05-18   AXP   86.720001   89.000000   85.919998   85.229942   \n",
              "0  2020-05-18    BA  126.180000  136.199997  125.800003  135.440002   \n",
              "0  2020-05-18   CAT  112.220001  115.660004  112.010002  108.081749   \n",
              "\n",
              "        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
              "0  135178400.0  0.0  2.628294   79.787533   65.136369  58.018337  128.081424   \n",
              "0    5631400.0  0.0  4.237348  222.581990  208.394304  53.511971   57.692987   \n",
              "0    7781700.0  0.0 -1.096790   90.298287   74.832442  48.085958   33.068757   \n",
              "0   43781800.0  0.0 -7.191083  142.655067  117.923934  42.534953  -29.016130   \n",
              "0    5603500.0  0.0 -1.169124  112.040902   96.223666  50.214111   17.694228   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
              "0  34.622794     70.754270     67.761639  29.299999   68.142733  \n",
              "0  31.990941    211.469554    198.274533  29.299999   68.142733  \n",
              "0   0.620002     83.116470     87.170146  29.299999   68.142733  \n",
              "0   4.926572    135.367000    164.372832  29.299999   68.142733  \n",
              "0   3.519003    106.144327    104.895563  29.299999   68.142733  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trade.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbFchno5j3xs",
        "outputId": "946fea4e-15e2-4611-9d14-01364e4ad00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_a2c\n",
        "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction( \n",
        "    environment = e_trade_gym,\n",
        "    model_name='a2c',\n",
        "    cwd='trained_models/a2c.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbYljWGjj3pH",
        "outputId": "65145e7d-15ff-4e62-94f9-e5256297d5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_ddpg\n",
        "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
        "    environment = e_trade_gym,\n",
        "    model_name='ddpg',\n",
        "    cwd='trained_models/ddpg.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74jNP2DBj3hb",
        "outputId": "f20ffd89-2b19-4340-9588-10e64a6b3b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_ppo\n",
        "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
        "    environment = e_trade_gym,\n",
        "    model_name='ppo',\n",
        "    cwd='trained_models/ppo.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7VyGGJPj3SH",
        "outputId": "a3b915fb-540f-4540-b0eb-c3ce085d59ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_td3\n",
        "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
        "    environment = e_trade_gym,\n",
        "    model_name='td3',\n",
        "    cwd='trained_models/td3.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLOnL5eYh1jR",
        "outputId": "0fa13ef0-b55f-4ca1-ac2c-e007913016ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_sac\n",
        "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
        "    environment = e_trade_gym,\n",
        "    model_name='sac',\n",
        "    cwd='trained_models/sac.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcE-t08w6DaW"
      },
      "source": [
        "<a id='7'></a>\n",
        "# Part 6.5: Mean Variance Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwEwkHJ1d_6u"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeVVbuwveJ_5"
      },
      "source": [
        "### Calculate mean returns and variance-covariance matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtesting Results\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "KeDeGAc9VrEg"
      },
      "outputs": [],
      "source": [
        "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
        "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
        "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
        "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
        "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
        "\n",
        "result = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True)\n",
        "result = pd.merge(result, df_result_td3, left_index=True, right_index=True)\n",
        "result = pd.merge(result, df_result_ppo, left_index=True, right_index=True)\n",
        "result = pd.merge(result, df_result_sac, left_index=True, right_index=True)\n",
        "result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annual return          0.131623\n",
            "Cumulative returns     0.421656\n",
            "Annual volatility      0.182048\n",
            "Sharpe ratio           0.771573\n",
            "Calmar ratio           0.669407\n",
            "Stability              0.527639\n",
            "Max drawdown          -0.196626\n",
            "Omega ratio            1.140118\n",
            "Sortino ratio          1.086976\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.017548\n",
            "Daily value at risk   -0.022378\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "perf_stats_sac = helper.backtest_stats(account_value = df_account_value_sac)\n",
        "perf_stats_sac = pd.DataFrame(perf_stats_sac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6xRfrqK4RVfq",
        "outputId": "868e3da5-3df9-4d54-b181-f630093210f2"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure()\n",
        "result.plot()\n",
        "plt.savefig(\"trained_models/models_\" + \".jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a2c</th>\n",
              "      <th>ddpg</th>\n",
              "      <th>td3</th>\n",
              "      <th>ppo</th>\n",
              "      <th>sac</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-03-22</th>\n",
              "      <td>1.287286e+06</td>\n",
              "      <td>1.261261e+06</td>\n",
              "      <td>1.339978e+06</td>\n",
              "      <td>1.231075e+06</td>\n",
              "      <td>1.421656e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     a2c          ddpg           td3           ppo  \\\n",
              "date                                                                 \n",
              "2023-03-22  1.287286e+06  1.261261e+06  1.339978e+06  1.231075e+06   \n",
              "\n",
              "                     sac  \n",
              "date                      \n",
              "2023-03-22  1.421656e+06  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annual return          0.131623\n",
            "Cumulative returns     0.421656\n",
            "Annual volatility      0.182048\n",
            "Sharpe ratio           0.771573\n",
            "Calmar ratio           0.669407\n",
            "Stability              0.527639\n",
            "Max drawdown          -0.196626\n",
            "Omega ratio            1.140118\n",
            "Sortino ratio          1.086976\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.017548\n",
            "Daily value at risk   -0.022378\n",
            "dtype: float64\n",
            "Annual return          0.084999\n",
            "Cumulative returns     0.261261\n",
            "Annual volatility      0.173730\n",
            "Sharpe ratio           0.557256\n",
            "Calmar ratio           0.381359\n",
            "Stability              0.259505\n",
            "Max drawdown          -0.222884\n",
            "Omega ratio            1.099290\n",
            "Sortino ratio          0.780667\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.918823\n",
            "Daily value at risk   -0.021504\n",
            "dtype: float64\n",
            "Annual return          0.075801\n",
            "Cumulative returns     0.231075\n",
            "Annual volatility      0.216230\n",
            "Sharpe ratio           0.446462\n",
            "Calmar ratio           0.259587\n",
            "Stability              0.075126\n",
            "Max drawdown          -0.292005\n",
            "Omega ratio            1.077465\n",
            "Sortino ratio          0.639430\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.028193\n",
            "Daily value at risk   -0.026859\n",
            "dtype: float64\n",
            "Annual return          0.108333\n",
            "Cumulative returns     0.339978\n",
            "Annual volatility      0.188574\n",
            "Sharpe ratio           0.640745\n",
            "Calmar ratio           0.424849\n",
            "Stability              0.147106\n",
            "Max drawdown          -0.254991\n",
            "Omega ratio            1.115301\n",
            "Sortino ratio          0.904269\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.006615\n",
            "Daily value at risk   -0.023279\n",
            "dtype: float64\n",
            "Annual return          0.092815\n",
            "Cumulative returns     0.287286\n",
            "Annual volatility      0.197272\n",
            "Sharpe ratio           0.549488\n",
            "Calmar ratio           0.337411\n",
            "Stability              0.281508\n",
            "Max drawdown          -0.275081\n",
            "Omega ratio            1.096259\n",
            "Sortino ratio          0.767980\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.039004\n",
            "Daily value at risk   -0.024424\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_sac = helper.backtest_stats(account_value = df_account_value_sac)\n",
        "perf_stats_sac = pd.DataFrame(perf_stats_sac)\n",
        "\n",
        "perf_stats_ddpg = helper.backtest_stats(account_value = df_account_value_ddpg)\n",
        "perf_stats_ddpg = pd.DataFrame(perf_stats_ddpg)\n",
        "\n",
        "perf_stats_ppo = helper.backtest_stats(account_value = df_account_value_ppo)\n",
        "perf_stats_ppo = pd.DataFrame(perf_stats_ppo)\n",
        "\n",
        "perf_stats_td3 = helper.backtest_stats(account_value = df_account_value_td3)\n",
        "perf_stats_td3 = pd.DataFrame(perf_stats_td3)\n",
        "\n",
        "perf_stats_a2c = helper.backtest_stats(account_value = df_account_value_a2c)\n",
        "perf_stats_a2c = pd.DataFrame(perf_stats_a2c)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (717, 8)\n",
            "Annual return          0.097242\n",
            "Cumulative returns     0.302176\n",
            "Annual volatility      0.172666\n",
            "Sharpe ratio           0.624822\n",
            "Calmar ratio           0.443201\n",
            "Stability              0.313422\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            1.112095\n",
            "Sortino ratio          0.873309\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.017392\n",
            "Daily value at risk   -0.021326\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "baseline_df = YahooDownloader(\n",
        "        ticker_list =[\"^DJI\"], \n",
        "        start_date = TRADE_START_DATE,\n",
        "        end_date = TRADE_END_DATE).fetch_data()\n",
        "\n",
        "stats = helper.backtest_stats(baseline_df, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "Annual_return_sac = perf_stats_sac.T['Annual return'][0]\n",
        "Annual_return_ppo = perf_stats_ppo.T['Annual return'][0]\n",
        "Annual_return_td3 = perf_stats_td3.T['Annual return'][0]\n",
        "Annual_return_ddpg = perf_stats_ddpg.T['Annual return'][0]\n",
        "Annual_return_a2c = perf_stats_a2c.T['Annual return'][0]\n",
        "Annual_return = stats[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "d = {'sac':Annual_return_sac, 'a2c':Annual_return_a2c, 'td3':Annual_return_td3, 'ddpg': Annual_return_ddpg, 'ppo':Annual_return_ppo}\n",
        "best_model = max(d.items(), key=lambda i: i[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'list' and 'int'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39mwhere(action \u001b[39m<\u001b[39;49m \u001b[39m-\u001b[39;49mmin_action)[\u001b[39m0\u001b[39m]\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'int'"
          ]
        }
      ],
      "source": [
        "np.where(action < -min_action)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-41,\n",
              " -1,\n",
              " 80,\n",
              " -89,\n",
              " 38,\n",
              " 2,\n",
              " -76,\n",
              " -21,\n",
              " -60,\n",
              " -79,\n",
              " 15,\n",
              " -71,\n",
              " 53,\n",
              " -25,\n",
              " -45,\n",
              " 73,\n",
              " 20,\n",
              " 61,\n",
              " -37,\n",
              " 68,\n",
              " 77,\n",
              " -65,\n",
              " 61,\n",
              " -11,\n",
              " 79,\n",
              " -2,\n",
              " -34,\n",
              " -90,\n",
              " -97]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "action = []\n",
        "for i in range(29):    \n",
        "    action.append(random.randint(-100, 100))\n",
        "min_action = 10\n",
        "action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "11\n",
            "13\n",
            "14\n",
            "18\n",
            "21\n",
            "23\n",
            "26\n",
            "27\n",
            "28\n"
          ]
        }
      ],
      "source": [
        "l = []\n",
        "for j in range(len(action)):\n",
        "    if action[j] < -min_action:\n",
        "        l.append(j)\n",
        "\n",
        "for index in l:\n",
        "    print(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from module.config import (\n",
        "    ALPACA_API_BASE_URL,\n",
        "    ALPACA_API_KEY,\n",
        "    ALPACA_API_SECRET,\n",
        "    INDICATORS,\n",
        "    TODAY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "ename": "HTTPError",
          "evalue": "403 Client Error: Forbidden for url: https://paper-api.alpaca.markets/v2/positions/AXP",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39malpaca_trade_api\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtradeapi\u001b[39;00m\n\u001b[1;32m      3\u001b[0m alpaca \u001b[39m=\u001b[39m tradeapi\u001b[39m.\u001b[39mREST(ALPACA_API_KEY,ALPACA_API_SECRET,ALPACA_API_BASE_URL, \u001b[39m'\u001b[39m\u001b[39mv2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m alpaca\u001b[39m.\u001b[39;49mget_position(\u001b[39m'\u001b[39;49m\u001b[39mAXP\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mqty\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/alpaca_trade_api/rest.py:504\u001b[0m, in \u001b[0;36mREST.get_position\u001b[0;34m(self, symbol)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_position\u001b[39m(\u001b[39mself\u001b[39m, symbol: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Position:\n\u001b[1;32m    503\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get an open position\"\"\"\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m/positions/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(symbol))\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_wrapper(resp, Position)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/alpaca_trade_api/rest.py:250\u001b[0m, in \u001b[0;36mREST.get\u001b[0;34m(self, path, data)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, path, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, path, data)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/alpaca_trade_api/rest.py:213\u001b[0m, in \u001b[0;36mREST._request\u001b[0;34m(self, method, path, data, base_url, api_version)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mwhile\u001b[39;00m retry \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    212\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_one_request(method, url, opts, retry)\n\u001b[1;32m    214\u001b[0m     \u001b[39mexcept\u001b[39;00m RetryException:\n\u001b[1;32m    215\u001b[0m         retry_wait \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_wait\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/alpaca_trade_api/rest.py:234\u001b[0m, in \u001b[0;36mREST._one_request\u001b[0;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[1;32m    232\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mrequest(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n\u001b[1;32m    233\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     resp\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    235\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m    236\u001b[0m     \u001b[39m# retry if we hit Rate Limit\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39min\u001b[39;00m retry_codes \u001b[39mand\u001b[39;00m retry \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://paper-api.alpaca.markets/v2/positions/AXP"
          ]
        }
      ],
      "source": [
        "import alpaca_trade_api as tradeapi\n",
        "\n",
        "alpaca = tradeapi.REST(ALPACA_API_KEY,ALPACA_API_SECRET,ALPACA_API_BASE_URL, 'v2')\n",
        "\n",
        "alpaca.get_position('AXP').qty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "from module.models import DRLAgent\n",
        "from module.env_stocktrading import StockTradingEnv\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import alpaca_trade_api as tradeapi\n",
        "import datetime\n",
        "import threading\n",
        "\n",
        "from module.processor_alpaca import AlpacaProcessor\n",
        "from module.config_tickers import DOW_30_TICKER\n",
        "\n",
        "from module.config import (\n",
        "    ALPACA_API_BASE_URL,\n",
        "    ALPACA_API_KEY,\n",
        "    ALPACA_API_SECRET,\n",
        "    INDICATORS,\n",
        "    TODAY\n",
        ")\n",
        "\n",
        "class Alpaca():\n",
        "\n",
        "    def __init__(self, model, turbulence_thresh=70):\n",
        "        self.model = model\n",
        "        self.turbulence_thresh = turbulence_thresh\n",
        "        self.time_interval = 60\n",
        "        try:\n",
        "            self.alpaca = tradeapi.REST(ALPACA_API_KEY,ALPACA_API_SECRET,ALPACA_API_BASE_URL, 'v2')\n",
        "        except:\n",
        "            raise ValueError('Fail to connect Alpaca. Please check account info and internet connection.')\n",
        "        \n",
        "        self.stocks = np.asarray([0] * len(DOW_30_TICKER[:-1])) #stocks holding\n",
        "        self.stocks_cd = np.zeros_like(self.stocks) \n",
        "        self.cash = None #cash record \n",
        "        self.stocks_df = pd.DataFrame(self.stocks, columns=['stocks'], index = DOW_30_TICKER[:-1])\n",
        "        self.asset_list = []\n",
        "        self.price = np.asarray([0] * len(DOW_30_TICKER[:-1]))\n",
        "        self.stockUniverse = DOW_30_TICKER[:-1]\n",
        "        self.turbulence_bool = 0\n",
        "        self.equities = []\n",
        "        self.max_stocks = int(0.0001*int(self.alpaca.get_account().cash))\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        orders = self.alpaca.list_orders(status=\"open\")\n",
        "        for order in orders:\n",
        "          self.alpaca.cancel_order(order.id)\n",
        "    \n",
        "        # Wait for market to open.\n",
        "        print(\"Waiting for market to open...\")\n",
        "        tAMO = threading.Thread(target=self.awaitMarketOpen)\n",
        "        tAMO.start()\n",
        "        tAMO.join()\n",
        "        print(\"Market opened.\")\n",
        "         # Figure out when the market will close so we can prepare to sell beforehand.\n",
        "        clock = self.alpaca.get_clock()\n",
        "        closingTime = clock.next_close.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "        currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "        self.timeToClose = closingTime - currTime\n",
        "    \n",
        "        while True:\n",
        "          \n",
        "          if(self.timeToClose < (60)):\n",
        "            # Close all positions when 1 minutes til market close.\n",
        "            print(\"Market closing soon. Stop trading.\")\n",
        "            break\n",
        "\n",
        "          else:\n",
        "            trade = threading.Thread(target=self.trade)\n",
        "            trade.start()\n",
        "            trade.join()\n",
        "            last_equity = float(self.alpaca.get_account().last_equity)\n",
        "            cur_time = time.time()\n",
        "            self.equities.append([cur_time,last_equity])\n",
        "            time.sleep(self.time_interval)\n",
        "\n",
        "    \n",
        "    def awaitMarketOpen(self):\n",
        "        isOpen = self.alpaca.get_clock().is_open\n",
        "\n",
        "        while(not isOpen):\n",
        "            clock = self.alpaca.get_clock()\n",
        "            openingTime = clock.next_open.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "            currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "            timeToOpen = int((openingTime - currTime) / 60)\n",
        "            print(str(timeToOpen) + \" minutes til market open.\")\n",
        "            time.sleep(60)\n",
        "            isOpen = self.alpaca.get_clock().is_open\n",
        "\n",
        "\n",
        "    def submitOrder(self, qty, stock, side, resp):\n",
        "        if(qty > 0):\n",
        "          try:\n",
        "            self.alpaca.submit_order(stock, qty, side, \"market\", \"day\")\n",
        "            print(\"Market order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | completed.\")\n",
        "            resp.append(True)\n",
        "          except:\n",
        "            print(\"Order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | did not go through.\")\n",
        "            resp.append(False)\n",
        "        else:\n",
        "          print(\"Quantity is 0, order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | not completed.\")\n",
        "          resp.append(True)\n",
        "    \n",
        "    def trade(self):\n",
        "        state = self.get_state()\n",
        "\n",
        "        action = self.model.predict(state)[0]\n",
        "        action = (action * self.max_stocks).astype(int)\n",
        "        \n",
        "        self.stocks_cd += 1\n",
        "        if self.turbulence_bool == 0:\n",
        "            min_action = 10  # stock_cd\n",
        "            for index in np.where(action < -min_action)[0]:  # sell_index:\n",
        "                sell_num_shares = min(self.stocks[index], -action[index])\n",
        "                qty =  abs(int(sell_num_shares))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'sell', respSO))\n",
        "                tSubmitOrder.start()\n",
        "                tSubmitOrder.join()\n",
        "                self.cash = float(self.alpaca.get_account().cash)\n",
        "                self.stocks_cd[index] = 0\n",
        "\n",
        "            for index in np.where(action > min_action)[0]:  # buy_index:\n",
        "                if self.cash < 0:\n",
        "                    tmp_cash = 0\n",
        "                else:\n",
        "                    tmp_cash = self.cash\n",
        "                buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n",
        "                if (buy_num_shares != buy_num_shares): # if buy_num_change = nan\n",
        "                    qty = 0 # set to 0 quantity\n",
        "                else:\n",
        "                    qty = abs(int(buy_num_shares))\n",
        "                qty = abs(int(buy_num_shares))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'buy', respSO))\n",
        "                tSubmitOrder.start()\n",
        "                tSubmitOrder.join()\n",
        "                self.cash = float(self.alpaca.get_account().cash)\n",
        "                self.stocks_cd[index] = 0\n",
        "                \n",
        "        else:  # sell all when turbulence\n",
        "            positions = self.alpaca.list_positions()\n",
        "            for position in positions:\n",
        "                if(position.side == 'long'):\n",
        "                    orderSide = 'sell'\n",
        "                else:\n",
        "                    orderSide = 'buy'\n",
        "                qty = abs(int(float(position.qty)))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
        "                tSubmitOrder.start()\n",
        "                tSubmitOrder.join()\n",
        "            \n",
        "            self.stocks_cd[:] = 0    \n",
        "       \n",
        "    def get_state(self):\n",
        "        stock_dimension = len(DOW_30_TICKER[:-1])\n",
        "        state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "\n",
        "        buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "        num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "        env_kwargs = {\n",
        "        \"hmax\": int(0.0001*int(self.alpaca.get_account().cash)),\n",
        "        \"initial_amount\": int(self.alpaca.get_account().cash),\n",
        "        \"num_stock_shares\": num_stock_shares,\n",
        "        \"buy_cost_pct\": buy_cost_list,\n",
        "        \"sell_cost_pct\": sell_cost_list,\n",
        "        \"state_space\": state_space,\n",
        "        \"stock_dim\": stock_dimension,\n",
        "        \"tech_indicator_list\": INDICATORS,\n",
        "        \"action_space\": stock_dimension,\n",
        "        \"reward_scaling\": 1e-4\n",
        "          }\n",
        "\n",
        "        processor = AlpacaProcessor(API_SECRET= ALPACA_API_SECRET, API_BASE_URL= ALPACA_API_BASE_URL, API_KEY=ALPACA_API_KEY)\n",
        "        d = pd.DataFrame(columns=['date', 'tic', 'open', 'high', 'low', 'close', 'volume', 'day', 'macd',\n",
        "       'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma',\n",
        "       'close_60_sma', 'vix', 'turbulence'])\n",
        "        d[\"tic\"] = DOW_30_TICKER\n",
        "        d = d.drop(d.index[len(d)-1])\n",
        "\n",
        "        data_df = pd.DataFrame()\n",
        "        for tic in DOW_30_TICKER[:-1]:\n",
        "            barset = self.alpaca.get_bars(tic, '1Min').df  # [tic]\n",
        "            barset[\"tic\"] = tic\n",
        "            barset = barset.reset_index()\n",
        "            data_df = pd.concat([barset, data_df])\n",
        "        data_df = data_df.reset_index()\n",
        "        start_time = data_df['timestamp'][0]\n",
        "        end_time = data_df['timestamp'][len(data_df)-1]\n",
        "\n",
        "        for tic in range(len(DOW_30_TICKER)-1):\n",
        "            tech, turb = processor.fetch_latest_data([DOW_30_TICKER[tic]], '1Min', INDICATORS, df = data_df, start_time = start_time, end_time = end_time)\n",
        "            turbulence_bool = 1 if turb >= self.turbulence_thresh else 0\n",
        "            turb = (self.sigmoid_sign(turb, self.turbulence_thresh) * 2 ** -5).astype(np.float32)\n",
        "            \n",
        "            dic = self.alpaca.get_latest_bar(DOW_30_TICKER[tic])\n",
        "            dic = eval('{' + str(dic)[10:-2].replace('\\n   ', '') + '}')\n",
        "            d.iloc[tic,2] =np.float64(dic['o'])\n",
        "            d.iloc[tic,3] = np.float64(dic['h'])\n",
        "            d.iloc[tic,4] = np.float64(dic['l'])\n",
        "            d.iloc[tic,5] = np.float64(dic['c'])\n",
        "            d.iloc[tic,6] = np.float64(dic['v'])\n",
        "            d.iloc[tic,-2] = np.float64(turb[0])\n",
        "            d.iloc[tic,-1] = np.float64(0)\n",
        "            d.iloc[tic, 0] = TODAY.strftime('%Y-%m-%d')\n",
        "            d.iloc[tic, 7] = np.float64(datetime.datetime.weekday(TODAY))\n",
        "            c = 0\n",
        "            for i in range(len(INDICATORS)):\n",
        "                d.iloc[tic,i+8] = np.float64(tech[c])\n",
        "                c+=1\n",
        "        d.index = d.date.factorize()[0]\n",
        "        d = d.fillna(0)\n",
        "        gym = StockTradingEnv(df = d, turbulence_threshold = self.turbulence_thresh,risk_indicator_col='vix', **env_kwargs)\n",
        "        env, obs = gym.get_sb_env()\n",
        "        return obs\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid_sign(ary, thresh):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
        "\n",
        "        return sigmoid(ary / thresh) * thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = Alpaca(model=trained_sac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(DOW_30_TICKER[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMNR5nHjh1iz",
        "uijiWgkuh1jB",
        "MRiOtrywfAo1",
        "_gDkU-j-fCmZ",
        "3Zpv4S0-fDBv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
