{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfv52r2G33jY"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/Stock_NeurIPS2018_SB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
        "\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Task Description](#0)\n",
        "* [2. Install Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. A List of Python Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download and Preprocess Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5. Build Market Environment in OpenAI Gym-style](#4)  \n",
        "    * [5.1. Data Split](#4.1)  \n",
        "    * [5.3. Environment for Training](#4.2)    \n",
        "* [6. Train DRL Agents](#5)\n",
        "* [7. Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Task Discription"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "We train a DRL agent for stock trading. This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
        "\n",
        "We specify the state-action-reward as follows:\n",
        "\n",
        "* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes many features and learns by interacting with the market environment (usually by replaying historical data).\n",
        "\n",
        "* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
        "\n",
        "\n",
        "**Market environment**: 30 consituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period.\n",
        "\n",
        "\n",
        "The data for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Install Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. A list of Python packages \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "658"
            ]
          },
          "execution_count": 327,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(len(trade)/29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPqeTTwoh1hn",
        "outputId": "23c28589-9d6f-4b8b-bf9e-9822e4ccea90"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../STOCK_DRL\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "from Processed import get_processed_data\n",
        "\n",
        "from module.yahoodownloader import YahooDownloader\n",
        "from module.preprocessor import FeatureEngineer, data_split\n",
        "from module.efficient_frontier import EfficientFrontier\n",
        "from module import helper\n",
        "from module.config_tickers import DOW_30_TICKER\n",
        "from module.env_stocktrading import StockTradingEnv\n",
        "from module.models import DRLAgent\n",
        "from module.logger import configure\n",
        "from module.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        "    \n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "RtUc_ofKmpdy"
      },
      "outputs": [],
      "source": [
        "from finrl.main import check_and_make_directories\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance provides stock data, financial news, financial reports, etc. Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** in FinRL-Meta to fetch data via Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h3XJnvrbLp-C",
        "outputId": "43a6df4b-1a4f-4835-a7d3-4f4da695f474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2020-07-01'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from config.py, TRAIN_START_DATE is a string\n",
        "TRAIN_START_DATE\n",
        "# from config.py, TRAIN_END_DATE is a string\n",
        "TRAIN_END_DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "9012549f-ac6c-48d3-9254-b162a53930a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (103961, 8)\n"
          ]
        }
      ],
      "source": [
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TRADE_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "c39fd69d-4815-416d-8bef-54dc7c6abcbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
          ]
        }
      ],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "5f69723b-2a5d-4d64-87c5-3a6d3abecd3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(103961, 8)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "7adbffad-04bf-4b83-d47e-6b25cb56efa6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.080002</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>43.832634</td>\n",
              "      <td>6547900</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>18.570000</td>\n",
              "      <td>19.520000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>15.365306</td>\n",
              "      <td>10955700</td>\n",
              "      <td>AXP</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>42.799999</td>\n",
              "      <td>45.560001</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>33.941090</td>\n",
              "      <td>7010200</td>\n",
              "      <td>BA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>46.980000</td>\n",
              "      <td>44.709999</td>\n",
              "      <td>31.579327</td>\n",
              "      <td>7117200</td>\n",
              "      <td>CAT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2009-01-02   3.067143   3.251429   3.041429   2.758535  746015200  AAPL   \n",
              "1  2009-01-02  58.590000  59.080002  57.750000  43.832634    6547900  AMGN   \n",
              "2  2009-01-02  18.570000  19.520000  18.400000  15.365306   10955700   AXP   \n",
              "3  2009-01-02  42.799999  45.560001  42.779999  33.941090    7010200    BA   \n",
              "4  2009-01-02  44.910000  46.980000  44.709999  31.579327    7117200   CAT   \n",
              "\n",
              "   day  \n",
              "0    4  \n",
              "1    4  \n",
              "2    4  \n",
              "3    4  \n",
              "4    4  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic'],ignore_index=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "We need to check for missing data and do feature engineering to convert the data point into a state.\n",
        "* **Adding technical indicators**. In practical trading, various information needs to be taken into account, such as historical prices, current holding shares, technical indicators, etc. Here, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* **Adding turbulence index**. Risk-aversion reflects whether an investor prefers to protect the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the turbulence index that measures extreme fluctuation of asset price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmKP-1ii3RLS",
        "outputId": "da44c66b-ec26-4950-c85c-2bd1aa80d8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3551, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = INDICATORS,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Kixon2tR3RLT"
      },
      "outputs": [],
      "source": [
        "list_ticker = processed[\"tic\"].unique().tolist()\n",
        "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
        "combination = list(itertools.product(list_date,list_ticker))\n",
        "\n",
        "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
        "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "processed_full = processed_full.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "grvhGJJII3Xn",
        "outputId": "935e319f-b7d8-4ed5-971d-05ef8c92e78b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>746015200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>2.758535</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.080002</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>43.832634</td>\n",
              "      <td>6547900.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.832634</td>\n",
              "      <td>43.832634</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AXP</td>\n",
              "      <td>18.570000</td>\n",
              "      <td>19.520000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>15.365306</td>\n",
              "      <td>10955700.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>15.365306</td>\n",
              "      <td>15.365306</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>BA</td>\n",
              "      <td>42.799999</td>\n",
              "      <td>45.560001</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>33.941090</td>\n",
              "      <td>7010200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>33.941090</td>\n",
              "      <td>33.941090</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CAT</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>46.980000</td>\n",
              "      <td>44.709999</td>\n",
              "      <td>31.579327</td>\n",
              "      <td>7117200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>31.579327</td>\n",
              "      <td>31.579327</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CRM</td>\n",
              "      <td>8.025000</td>\n",
              "      <td>8.550000</td>\n",
              "      <td>7.912500</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>4069200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CSCO</td>\n",
              "      <td>16.410000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.250000</td>\n",
              "      <td>11.948338</td>\n",
              "      <td>40980600.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>11.948338</td>\n",
              "      <td>11.948338</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CVX</td>\n",
              "      <td>74.230003</td>\n",
              "      <td>77.300003</td>\n",
              "      <td>73.580002</td>\n",
              "      <td>43.677189</td>\n",
              "      <td>13695900.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>43.677189</td>\n",
              "      <td>43.677189</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>DIS</td>\n",
              "      <td>22.760000</td>\n",
              "      <td>24.030001</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>9796600.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>GS</td>\n",
              "      <td>84.019997</td>\n",
              "      <td>87.620003</td>\n",
              "      <td>82.190002</td>\n",
              "      <td>69.747612</td>\n",
              "      <td>14088500.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.981391</td>\n",
              "      <td>2.6521</td>\n",
              "      <td>100.0</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.0</td>\n",
              "      <td>69.747612</td>\n",
              "      <td>69.747612</td>\n",
              "      <td>39.189999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic       open       high        low      close       volume  \\\n",
              "0  2009-01-02  AAPL   3.067143   3.251429   3.041429   2.758535  746015200.0   \n",
              "1  2009-01-02  AMGN  58.590000  59.080002  57.750000  43.832634    6547900.0   \n",
              "2  2009-01-02   AXP  18.570000  19.520000  18.400000  15.365306   10955700.0   \n",
              "3  2009-01-02    BA  42.799999  45.560001  42.779999  33.941090    7010200.0   \n",
              "4  2009-01-02   CAT  44.910000  46.980000  44.709999  31.579327    7117200.0   \n",
              "5  2009-01-02   CRM   8.025000   8.550000   7.912500   8.505000    4069200.0   \n",
              "6  2009-01-02  CSCO  16.410000  17.000000  16.250000  11.948338   40980600.0   \n",
              "7  2009-01-02   CVX  74.230003  77.300003  73.580002  43.677189   13695900.0   \n",
              "8  2009-01-02   DIS  22.760000  24.030001  22.500000  20.597494    9796600.0   \n",
              "9  2009-01-02    GS  84.019997  87.620003  82.190002  69.747612   14088500.0   \n",
              "\n",
              "   day  macd   boll_ub  boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
              "0  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0      2.758535   \n",
              "1  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     43.832634   \n",
              "2  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     15.365306   \n",
              "3  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     33.941090   \n",
              "4  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     31.579327   \n",
              "5  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0      8.505000   \n",
              "6  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     11.948338   \n",
              "7  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     43.677189   \n",
              "8  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     20.597494   \n",
              "9  4.0   0.0  2.981391   2.6521   100.0  66.666667  100.0     69.747612   \n",
              "\n",
              "   close_60_sma        vix  turbulence  \n",
              "0      2.758535  39.189999         0.0  \n",
              "1     43.832634  39.189999         0.0  \n",
              "2     15.365306  39.189999         0.0  \n",
              "3     33.941090  39.189999         0.0  \n",
              "4     31.579327  39.189999         0.0  \n",
              "5      8.505000  39.189999         0.0  \n",
              "6     11.948338  39.189999         0.0  \n",
              "7     43.677189  39.189999         0.0  \n",
              "8     20.597494  39.189999         0.0  \n",
              "9     69.747612  39.189999         0.0  "
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "5vdORQ384Qx-"
      },
      "outputs": [],
      "source": [
        "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3551"
            ]
          },
          "execution_count": 323,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int(len(mvo_df)/29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Build A Market Environment in OpenAI Gym-style\n",
        "The training process involves observing stock price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
        "\n",
        "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TOhcryx44bb"
      },
      "source": [
        "## Data Split\n",
        "We split the data into training set and testing set as follows:\n",
        "\n",
        "Training data period: 2009-01-01 to 2020-07-01\n",
        "\n",
        "Trading data period: 2020-07-01 to 2021-10-31\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qaVGjLtgbI",
        "outputId": "99d9a9eb-68ca-4e0b-f29a-16aeefe05693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83897\n",
            "19082\n"
          ]
        }
      ],
      "source": [
        "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
        "print(len(train))\n",
        "print(len(trade))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "p52zNCOhTtLR",
        "outputId": "22263b87-b851-4d0d-a584-8572bca8ff0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2892</th>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>UNH</td>\n",
              "      <td>288.570007</td>\n",
              "      <td>296.450012</td>\n",
              "      <td>287.660004</td>\n",
              "      <td>284.978790</td>\n",
              "      <td>2932900.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.019287</td>\n",
              "      <td>300.970827</td>\n",
              "      <td>268.613865</td>\n",
              "      <td>52.413059</td>\n",
              "      <td>-25.914719</td>\n",
              "      <td>1.846804</td>\n",
              "      <td>285.220270</td>\n",
              "      <td>278.269271</td>\n",
              "      <td>30.43</td>\n",
              "      <td>12.918757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2892</th>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>V</td>\n",
              "      <td>191.490005</td>\n",
              "      <td>193.750000</td>\n",
              "      <td>190.160004</td>\n",
              "      <td>189.604019</td>\n",
              "      <td>9040100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.042556</td>\n",
              "      <td>197.569696</td>\n",
              "      <td>183.942024</td>\n",
              "      <td>53.021034</td>\n",
              "      <td>-51.608286</td>\n",
              "      <td>2.013358</td>\n",
              "      <td>190.347375</td>\n",
              "      <td>180.598288</td>\n",
              "      <td>30.43</td>\n",
              "      <td>12.918757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2892</th>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>VZ</td>\n",
              "      <td>54.919998</td>\n",
              "      <td>55.290001</td>\n",
              "      <td>54.360001</td>\n",
              "      <td>48.169010</td>\n",
              "      <td>17414800.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.417955</td>\n",
              "      <td>51.555486</td>\n",
              "      <td>46.593788</td>\n",
              "      <td>48.097037</td>\n",
              "      <td>-51.186723</td>\n",
              "      <td>8.508886</td>\n",
              "      <td>48.776547</td>\n",
              "      <td>49.209270</td>\n",
              "      <td>30.43</td>\n",
              "      <td>12.918757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2892</th>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>WBA</td>\n",
              "      <td>42.119999</td>\n",
              "      <td>42.580002</td>\n",
              "      <td>41.759998</td>\n",
              "      <td>37.630482</td>\n",
              "      <td>4782100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.080963</td>\n",
              "      <td>41.075411</td>\n",
              "      <td>35.173593</td>\n",
              "      <td>48.830183</td>\n",
              "      <td>-14.613203</td>\n",
              "      <td>1.500723</td>\n",
              "      <td>37.726358</td>\n",
              "      <td>37.533500</td>\n",
              "      <td>30.43</td>\n",
              "      <td>12.918757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2892</th>\n",
              "      <td>2020-06-30</td>\n",
              "      <td>WMT</td>\n",
              "      <td>119.220001</td>\n",
              "      <td>120.129997</td>\n",
              "      <td>118.540001</td>\n",
              "      <td>115.184006</td>\n",
              "      <td>6836400.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.879410</td>\n",
              "      <td>118.508925</td>\n",
              "      <td>112.593777</td>\n",
              "      <td>48.159674</td>\n",
              "      <td>-69.964752</td>\n",
              "      <td>3.847271</td>\n",
              "      <td>116.836409</td>\n",
              "      <td>118.756425</td>\n",
              "      <td>30.43</td>\n",
              "      <td>12.918757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            date  tic        open        high         low       close  \\\n",
              "2892  2020-06-30  UNH  288.570007  296.450012  287.660004  284.978790   \n",
              "2892  2020-06-30    V  191.490005  193.750000  190.160004  189.604019   \n",
              "2892  2020-06-30   VZ   54.919998   55.290001   54.360001   48.169010   \n",
              "2892  2020-06-30  WBA   42.119999   42.580002   41.759998   37.630482   \n",
              "2892  2020-06-30  WMT  119.220001  120.129997  118.540001  115.184006   \n",
              "\n",
              "          volume  day      macd     boll_ub     boll_lb     rsi_30     cci_30  \\\n",
              "2892   2932900.0  1.0 -0.019287  300.970827  268.613865  52.413059 -25.914719   \n",
              "2892   9040100.0  1.0  1.042556  197.569696  183.942024  53.021034 -51.608286   \n",
              "2892  17414800.0  1.0 -0.417955   51.555486   46.593788  48.097037 -51.186723   \n",
              "2892   4782100.0  1.0 -0.080963   41.075411   35.173593  48.830183 -14.613203   \n",
              "2892   6836400.0  1.0 -0.879410  118.508925  112.593777  48.159674 -69.964752   \n",
              "\n",
              "         dx_30  close_30_sma  close_60_sma    vix  turbulence  \n",
              "2892  1.846804    285.220270    278.269271  30.43   12.918757  \n",
              "2892  2.013358    190.347375    180.598288  30.43   12.918757  \n",
              "2892  8.508886     48.776547     49.209270  30.43   12.918757  \n",
              "2892  1.500723     37.726358     37.533500  30.43   12.918757  \n",
              "2892  3.847271    116.836409    118.756425  30.43   12.918757  "
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "k9zU9YaTTvFq",
        "outputId": "f8289fe9-674a-4456-aaea-9d021ddbb5a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>91.279999</td>\n",
              "      <td>91.839996</td>\n",
              "      <td>90.977501</td>\n",
              "      <td>89.494553</td>\n",
              "      <td>110737200.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.000854</td>\n",
              "      <td>92.276538</td>\n",
              "      <td>79.814266</td>\n",
              "      <td>62.807128</td>\n",
              "      <td>107.498985</td>\n",
              "      <td>29.730532</td>\n",
              "      <td>83.550962</td>\n",
              "      <td>77.363088</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>235.520004</td>\n",
              "      <td>256.230011</td>\n",
              "      <td>232.580002</td>\n",
              "      <td>234.614304</td>\n",
              "      <td>6575800.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.552511</td>\n",
              "      <td>227.036704</td>\n",
              "      <td>195.594648</td>\n",
              "      <td>61.279625</td>\n",
              "      <td>270.848998</td>\n",
              "      <td>46.806139</td>\n",
              "      <td>209.902523</td>\n",
              "      <td>210.950772</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>AXP</td>\n",
              "      <td>95.250000</td>\n",
              "      <td>96.959999</td>\n",
              "      <td>93.639999</td>\n",
              "      <td>91.078468</td>\n",
              "      <td>3301000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.384903</td>\n",
              "      <td>109.215321</td>\n",
              "      <td>86.798779</td>\n",
              "      <td>48.504819</td>\n",
              "      <td>-66.306151</td>\n",
              "      <td>3.142448</td>\n",
              "      <td>96.180265</td>\n",
              "      <td>89.702836</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>BA</td>\n",
              "      <td>185.880005</td>\n",
              "      <td>190.610001</td>\n",
              "      <td>180.039993</td>\n",
              "      <td>180.320007</td>\n",
              "      <td>49036700.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.443193</td>\n",
              "      <td>220.721139</td>\n",
              "      <td>160.932863</td>\n",
              "      <td>50.925771</td>\n",
              "      <td>24.220608</td>\n",
              "      <td>15.932920</td>\n",
              "      <td>176.472335</td>\n",
              "      <td>155.614168</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>CAT</td>\n",
              "      <td>129.380005</td>\n",
              "      <td>129.399994</td>\n",
              "      <td>125.879997</td>\n",
              "      <td>118.455788</td>\n",
              "      <td>2807800.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.249466</td>\n",
              "      <td>128.246931</td>\n",
              "      <td>111.290116</td>\n",
              "      <td>52.865418</td>\n",
              "      <td>35.692958</td>\n",
              "      <td>14.457404</td>\n",
              "      <td>117.239535</td>\n",
              "      <td>111.578318</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic        open        high         low       close  \\\n",
              "0  2020-07-01  AAPL   91.279999   91.839996   90.977501   89.494553   \n",
              "0  2020-07-01  AMGN  235.520004  256.230011  232.580002  234.614304   \n",
              "0  2020-07-01   AXP   95.250000   96.959999   93.639999   91.078468   \n",
              "0  2020-07-01    BA  185.880005  190.610001  180.039993  180.320007   \n",
              "0  2020-07-01   CAT  129.380005  129.399994  125.879997  118.455788   \n",
              "\n",
              "        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
              "0  110737200.0  2.0  3.000854   92.276538   79.814266  62.807128  107.498985   \n",
              "0    6575800.0  2.0  3.552511  227.036704  195.594648  61.279625  270.848998   \n",
              "0    3301000.0  2.0 -0.384903  109.215321   86.798779  48.504819  -66.306151   \n",
              "0   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   24.220608   \n",
              "0    2807800.0  2.0  1.249466  128.246931  111.290116  52.865418   35.692958   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
              "0  29.730532     83.550962     77.363088  28.620001   53.068112  \n",
              "0  46.806139    209.902523    210.950772  28.620001   53.068112  \n",
              "0   3.142448     96.180265     89.702836  28.620001   53.068112  \n",
              "0  15.932920    176.472335    155.614168  28.620001   53.068112  \n",
              "0  14.457404    117.239535    111.578318  28.620001   53.068112  "
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trade.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYN573SOHhxG",
        "outputId": "e8e3426a-3f41-4153-c5ff-80b9a997c9ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma']"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INDICATORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "0d415071-8d51-42f9-b141-f2122e272da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}\n",
        "\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64EoqOrQjiVf"
      },
      "source": [
        "## Environment for Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwSvvPjutpqS",
        "outputId": "78c63dfc-e3c8-4d7a-f807-4ce7058d5384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Train DRL Agents\n",
        "* The DRL algorithms are from **Stable Baselines 3**. Users are also encouraged to try **ElegantRL** and **Ray RLlib**.\n",
        "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "364PsqckttcQ"
      },
      "outputs": [],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "if_using_a2c = True\n",
        "if_using_ddpg = True\n",
        "if_using_ppo = True\n",
        "if_using_td3 = True\n",
        "if_using_sac = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDmqOyF9h1iz"
      },
      "source": [
        "### Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uijiWgkuh1jB"
      },
      "source": [
        "### Agent 1: A2C\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUCnkn-HIbmj",
        "outputId": "8be899ae-c772-46fd-e613-92dacfa9ed4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
            "Using cpu device\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-24 11:30:04.330726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-24 11:30:06.846584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/acraf/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-02-24 11:30:06.846831: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/acraf/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-02-24 11:30:06.846847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to results/a2c\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_a2c = agent.get_model(\"a2c\")\n",
        "\n",
        "if if_using_a2c:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/a2c'\n",
        "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_a2c.set_logger(new_logger_a2c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GVpkWGqH4-D",
        "outputId": "4772e493-7857-4ea6-e091-a8fbc665f06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 107        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.0175     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -38.9      |\n",
            "|    reward             | 0.45019418 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.45       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 110        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.187     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -18        |\n",
            "|    reward             | -1.3892226 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.73       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 110       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -269      |\n",
            "|    reward             | 8.273318  |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 45.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 108       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -24.5     |\n",
            "|    reward             | -0.599003 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 9.97      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 104        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 904        |\n",
            "|    reward             | -12.767281 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 566        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 105         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | -0.00824    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 132         |\n",
            "|    reward             | -0.09445826 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 10.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.0244    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -125       |\n",
            "|    reward             | -2.5293415 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10.2       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 106        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.206     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -47.4      |\n",
            "|    reward             | -2.3676472 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.7        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 107        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -2.46e-05  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 241        |\n",
            "|    reward             | -2.2146397 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 43         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 107        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -11.4      |\n",
            "|    reward             | -2.4411218 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.04       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 107        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 51         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 94.1       |\n",
            "|    reward             | -3.0870364 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 30.4       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 107         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 56          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -95.5       |\n",
            "|    reward             | 0.032396942 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 5.87        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 107       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.7     |\n",
            "|    explained_variance | 0.0303    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 82        |\n",
            "|    reward             | -4.934081 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 8.85      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 107       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -192      |\n",
            "|    reward             | 2.3310452 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 49.2      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 107      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -163     |\n",
            "|    reward             | 5.702532 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 29.7     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 107      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -250     |\n",
            "|    reward             | 3.558028 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 61.4     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 107       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0.0185    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 141       |\n",
            "|    reward             | 43.384083 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 39.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 109       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.631    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -29.1     |\n",
            "|    reward             | 0.7330552 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.05      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 110          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.6        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 201          |\n",
            "|    reward             | -0.112113304 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 25.9         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 111        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.7      |\n",
            "|    explained_variance | -0.0931    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -146       |\n",
            "|    reward             | -2.0756536 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 15         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 112       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.7     |\n",
            "|    explained_variance | 0.0914    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 44.5      |\n",
            "|    reward             | 2.3420038 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.53      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 112        |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 97         |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.7      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | -39.1      |\n",
            "|    reward             | -10.356104 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 5.51       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 113       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | -3.51e+03 |\n",
            "|    reward             | 21.482555 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 7.1e+03   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 105       |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 89.3      |\n",
            "|    reward             | 0.9353563 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 10.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 114        |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 109        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | -6.99      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | -126       |\n",
            "|    reward             | -0.3437684 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 10.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 4.68      |\n",
            "|    reward             | 1.8175603 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.0975    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 114        |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 118        |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | -25.6      |\n",
            "|    reward             | -1.5511049 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.905      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 715       |\n",
            "|    reward             | 3.2366195 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 362       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 114       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | -69.9     |\n",
            "|    reward             | 1.4336029 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.2       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 115        |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 130        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | -0.0928    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | 80.9       |\n",
            "|    reward             | 0.57258254 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 4.63       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 115         |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 134         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | 55.3        |\n",
            "|    reward             | -0.91466194 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 2.51        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 115        |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 138        |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | -15.2      |\n",
            "|    reward             | -3.0508401 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 6.95       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 115       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 142       |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | -52.7     |\n",
            "|    reward             | 1.6376741 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.49      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 115        |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 146        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | 258        |\n",
            "|    reward             | -3.4196663 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 52.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 150       |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 0.144     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 59.2      |\n",
            "|    reward             | 0.1366644 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.46      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 116       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 154       |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | -35.9     |\n",
            "|    reward             | 1.7360989 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.83      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 114        |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 161        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 118        |\n",
            "|    reward             | 0.44737977 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 10         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 112        |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 168        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | 179        |\n",
            "|    reward             | 0.07414136 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 20.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 112       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 173       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | -46.1     |\n",
            "|    reward             | 2.1899374 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.11      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 112       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 178       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -82       |\n",
            "|    reward             | 4.0844927 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 5.56      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 111        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 183        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 1.61       |\n",
            "|    reward             | 0.14829318 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.825      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 111        |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 187        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | -67.7      |\n",
            "|    reward             | 0.70372653 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.9        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 112      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 191      |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | -97.6    |\n",
            "|    reward             | 2.572025 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 5.95     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 112       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 196       |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 204       |\n",
            "|    reward             | 2.6079452 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 22.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 111         |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 201         |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 56.4        |\n",
            "|    reward             | -0.13677862 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 2.5         |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 110       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 207       |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | -31.7     |\n",
            "|    reward             | 0.7207669 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.11      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 110       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 213       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -140      |\n",
            "|    reward             | 0.5990945 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 14.8      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 109         |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 218         |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.1       |\n",
            "|    explained_variance | 0.0364      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | -112        |\n",
            "|    reward             | -0.85724545 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 9.46        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 109       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 224       |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | -61       |\n",
            "|    reward             | 0.2801285 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.56      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 108        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 229        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -150       |\n",
            "|    reward             | -1.0386707 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 18.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 108       |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 235       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 107       |\n",
            "|    reward             | 1.8251842 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 31.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 107       |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 240       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | -506      |\n",
            "|    reward             | 3.5508463 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 157       |\n",
            "-------------------------------------\n",
            "day: 2892, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5705118.21\n",
            "total_reward: 4705118.21\n",
            "total_cost: 102288.59\n",
            "total_trades: 54847\n",
            "Sharpe: 0.944\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 107        |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 246        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | -0.0683    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | -98.9      |\n",
            "|    reward             | 0.08941965 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 6.38       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 106         |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 252         |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.9       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | -144        |\n",
            "|    reward             | -0.89369416 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 12.1        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 106       |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 258       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | -0.199    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | -24.1     |\n",
            "|    reward             | 2.7836196 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 10.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | 0.098      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -135       |\n",
            "|    reward             | 0.81684816 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 14.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 270        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | 0.00235    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -125       |\n",
            "|    reward             | 0.46977153 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 12.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 104       |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 276       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | -0.198    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | -9.47     |\n",
            "|    reward             | 1.0718989 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.83      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 103         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 283         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42         |\n",
            "|    explained_variance | 0.0343      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | 12.7        |\n",
            "|    reward             | -0.16700801 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.496       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 103        |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 289        |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | -0.0289    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | 27.6       |\n",
            "|    reward             | -0.6205297 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.38       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 103      |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 293      |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42      |\n",
            "|    explained_variance | 0.321    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | -44.3    |\n",
            "|    reward             | -4.38469 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 5.54     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 103        |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 299        |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -305       |\n",
            "|    reward             | -1.6120754 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 51.7       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 103      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 305      |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42      |\n",
            "|    explained_variance | 0.176    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | 59.3     |\n",
            "|    reward             | 1.788206 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 5.72     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 102      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 312      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42      |\n",
            "|    explained_variance | 1.13e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 66.1     |\n",
            "|    reward             | 1.617952 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 4.3      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 102        |\n",
            "|    iterations         | 6500       |\n",
            "|    time_elapsed       | 317        |\n",
            "|    total_timesteps    | 32500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | -0.0233    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6499       |\n",
            "|    policy_loss        | 24.1       |\n",
            "|    reward             | -3.9803324 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 3.29       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 102       |\n",
            "|    iterations         | 6600      |\n",
            "|    time_elapsed       | 322       |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6599      |\n",
            "|    policy_loss        | -36.3     |\n",
            "|    reward             | 0.0834081 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.59      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 329       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | -0.101    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -688      |\n",
            "|    reward             | -4.845575 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 291       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 334         |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | -86.9       |\n",
            "|    reward             | -0.87097204 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 5.33        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 340         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | -156        |\n",
            "|    reward             | -0.65553415 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 19.2        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 345        |\n",
            "|    total_timesteps    | 35000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6999       |\n",
            "|    policy_loss        | 16.8       |\n",
            "|    reward             | -0.1778165 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.314      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 350        |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0.000385   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -26.2      |\n",
            "|    reward             | 0.28358352 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.453      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 355       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7199      |\n",
            "|    policy_loss        | -258      |\n",
            "|    reward             | 2.2616026 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 42.4      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 361         |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 351         |\n",
            "|    reward             | -0.35121036 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 110         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 367        |\n",
            "|    total_timesteps    | 37000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7399       |\n",
            "|    policy_loss        | -472       |\n",
            "|    reward             | -4.1948423 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 121        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 7500       |\n",
            "|    time_elapsed       | 373        |\n",
            "|    total_timesteps    | 37500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7499       |\n",
            "|    policy_loss        | 252        |\n",
            "|    reward             | -2.8471646 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 40.8       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 100          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 379          |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -42.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | -84.5        |\n",
            "|    reward             | -0.034833975 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 4.17         |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 384      |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.3    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | 14.9     |\n",
            "|    reward             | 1.53396  |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.277    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 389        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | -23.5      |\n",
            "|    reward             | -1.4710889 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.41       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 7900     |\n",
            "|    time_elapsed       | 394      |\n",
            "|    total_timesteps    | 39500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.4    |\n",
            "|    explained_variance | -0.0108  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7899     |\n",
            "|    policy_loss        | 157      |\n",
            "|    reward             | 2.197683 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 22.8     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 399       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | 29.6      |\n",
            "|    reward             | 0.5108606 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 3.94      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 403       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 241       |\n",
            "|    reward             | 5.0616813 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 38.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 408        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.4      |\n",
            "|    explained_variance | 5.54e-06   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | 60.5       |\n",
            "|    reward             | 0.10438065 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.92       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 413        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | 102        |\n",
            "|    reward             | -1.3704057 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.3        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 418       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | -70.1     |\n",
            "|    reward             | -4.204975 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 5.7       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 100         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 423         |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.4       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | 378         |\n",
            "|    reward             | -0.21193725 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 94.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 8600       |\n",
            "|    time_elapsed       | 428        |\n",
            "|    total_timesteps    | 43000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.4      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8599       |\n",
            "|    policy_loss        | 652        |\n",
            "|    reward             | -20.792934 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 255        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 100         |\n",
            "|    iterations         | 8700        |\n",
            "|    time_elapsed       | 433         |\n",
            "|    total_timesteps    | 43500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | -0.011      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8699        |\n",
            "|    policy_loss        | 13.7        |\n",
            "|    reward             | 0.119079955 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.04        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 8800       |\n",
            "|    time_elapsed       | 437        |\n",
            "|    total_timesteps    | 44000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 0.179      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8799       |\n",
            "|    policy_loss        | -54.4      |\n",
            "|    reward             | 0.40140614 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.58       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 442      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | -94.2    |\n",
            "|    reward             | 1.510868 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 5.71     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 448        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 0.664      |\n",
            "|    reward             | -0.7485255 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 1.62       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 453       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | 24        |\n",
            "|    reward             | 1.2469056 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.43      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 457      |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.7    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | -58.4    |\n",
            "|    reward             | 8.423774 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 9.17     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 463        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.6      |\n",
            "|    explained_variance | -0.00499   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | -194       |\n",
            "|    reward             | 0.11417168 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 19         |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 100         |\n",
            "|    iterations         | 9400        |\n",
            "|    time_elapsed       | 469         |\n",
            "|    total_timesteps    | 47000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.7       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9399        |\n",
            "|    policy_loss        | 141         |\n",
            "|    reward             | -0.67849505 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 11.3        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 100         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 474         |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | -340        |\n",
            "|    reward             | -0.08376478 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 68.5        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 481        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 64         |\n",
            "|    reward             | -4.4609494 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 42.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 99        |\n",
            "|    iterations         | 9700      |\n",
            "|    time_elapsed       | 486       |\n",
            "|    total_timesteps    | 48500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9699      |\n",
            "|    policy_loss        | -222      |\n",
            "|    reward             | 2.6373625 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 30.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 491        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | 257        |\n",
            "|    reward             | -0.7577431 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 51.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 497        |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.7      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | 61.9       |\n",
            "|    reward             | 0.48284057 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.12       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 501        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | 13.5       |\n",
            "|    reward             | -0.6008491 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.31       |\n",
            "--------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                             tb_log_name='a2c',\n",
        "                             total_timesteps=50000) if if_using_a2c else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRiOtrywfAo1"
      },
      "source": [
        "### Agent 2: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2YadjfnLwgt",
        "outputId": "2daa7acb-8985-4122-84ca-74537316bef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/ddpg\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "model_ddpg = agent.get_model(\"ddpg\")\n",
        "\n",
        "if if_using_ddpg:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ddpg'\n",
        "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ddpg.set_logger(new_logger_ddpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDa78rqfO_a",
        "outputId": "5ef7cb2f-7665-4266-8fab-2f9534de43cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 2892, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3702468.75\n",
            "total_reward: 2702468.75\n",
            "total_cost: 5120.89\n",
            "total_trades: 36610\n",
            "Sharpe: 0.751\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 54        |\n",
            "|    time_elapsed    | 213       |\n",
            "|    total_timesteps | 11572     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -46       |\n",
            "|    critic_loss     | 169       |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8679      |\n",
            "|    reward          | 2.2028034 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 52        |\n",
            "|    time_elapsed    | 441       |\n",
            "|    total_timesteps | 23144     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -31.6     |\n",
            "|    critic_loss     | 6.29      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 20251     |\n",
            "|    reward          | 2.2028034 |\n",
            "----------------------------------\n",
            "day: 2892, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4311284.72\n",
            "total_reward: 3311284.72\n",
            "total_cost: 999.00\n",
            "total_trades: 46272\n",
            "Sharpe: 0.773\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 52        |\n",
            "|    time_elapsed    | 667       |\n",
            "|    total_timesteps | 34716     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -22.4     |\n",
            "|    critic_loss     | 3.31      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 31823     |\n",
            "|    reward          | 2.2028034 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 51        |\n",
            "|    time_elapsed    | 896       |\n",
            "|    total_timesteps | 46288     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -17.3     |\n",
            "|    critic_loss     | 2.03      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 43395     |\n",
            "|    reward          | 2.2028034 |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=50000) if if_using_ddpg else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gDkU-j-fCmZ"
      },
      "source": [
        "### Agent 3: PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5D5PFUhMzSV",
        "outputId": "54d861fd-b7d5-47f1-e0d6-fe8301a6fee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to results/ppo\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "\n",
        "if if_using_ppo:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/ppo'\n",
        "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_ppo.set_logger(new_logger_ppo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt8eIQKYM4G3",
        "outputId": "52802a60-c084-4d89-96cf-b645177f7161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 110         |\n",
            "|    iterations           | 1           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 2048        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024190363 |\n",
            "|    clip_fraction        | 0.195       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | 0.0116      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 44.4        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0121     |\n",
            "|    reward               | 0.49708298  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 58.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 110         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021935904 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | 0.0608      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.07        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0188     |\n",
            "|    reward               | 0.72516423  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 117         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023881072 |\n",
            "|    clip_fraction        | 0.193       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | -0.00418    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 38.6        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    reward               | -1.4426881  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 62.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 116         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 70          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021975743 |\n",
            "|    clip_fraction        | 0.258       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.00929     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 13.5        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    reward               | 4.6637483   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 61.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 117         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023009941 |\n",
            "|    clip_fraction        | 0.237       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.4       |\n",
            "|    explained_variance   | 0.124       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.52        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0125     |\n",
            "|    reward               | 3.04133     |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 15.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 119         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026988719 |\n",
            "|    clip_fraction        | 0.24        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.4       |\n",
            "|    explained_variance   | 0.0258      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 27.8        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    reward               | 1.6779461   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 39.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 121         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 117         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026414942 |\n",
            "|    clip_fraction        | 0.242       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.0164      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 38.1        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    reward               | 1.7610744   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 97          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 124         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 131         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031101022 |\n",
            "|    clip_fraction        | 0.235       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.0305      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 11.5        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0123     |\n",
            "|    reward               | 0.30927432  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 25.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 126         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 146         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028573485 |\n",
            "|    clip_fraction        | 0.265       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.0135      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 26.8        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0109     |\n",
            "|    reward               | 0.4661443   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 56.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 127         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 161         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027712347 |\n",
            "|    clip_fraction        | 0.262       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.0298      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 37.9        |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00974    |\n",
            "|    reward               | 0.86316705  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 56.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 127         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024112169 |\n",
            "|    clip_fraction        | 0.232       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.6       |\n",
            "|    explained_variance   | 0.00668     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 45.6        |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00798    |\n",
            "|    reward               | 4.3011303   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 130         |\n",
            "-----------------------------------------\n",
            "day: 2892, episode: 60\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3891536.51\n",
            "total_reward: 2891536.51\n",
            "total_cost: 310917.12\n",
            "total_trades: 78059\n",
            "Sharpe: 0.779\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 127         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 192         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024889363 |\n",
            "|    clip_fraction        | 0.242       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.6       |\n",
            "|    explained_variance   | 0.0697      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.09        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0191     |\n",
            "|    reward               | -0.06193529 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 20.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 128        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 207        |\n",
            "|    total_timesteps      | 26624      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03676385 |\n",
            "|    clip_fraction        | 0.281      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42.7      |\n",
            "|    explained_variance   | 0.0164     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 45.9       |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.00351   |\n",
            "|    reward               | 0.29445314 |\n",
            "|    std                  | 1.06       |\n",
            "|    value_loss           | 68.7       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 129         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 221         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034023464 |\n",
            "|    clip_fraction        | 0.259       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.8       |\n",
            "|    explained_variance   | 0.0369      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 51.1        |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.00583    |\n",
            "|    reward               | -2.0730233  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 126         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 128         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 238         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025636028 |\n",
            "|    clip_fraction        | 0.275       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.9       |\n",
            "|    explained_variance   | 0.00201     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 16.9        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00176    |\n",
            "|    reward               | 4.6274858   |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 35.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 128          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 255          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018864386  |\n",
            "|    clip_fraction        | 0.175        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42.9        |\n",
            "|    explained_variance   | 0.0475       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 29.2         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00957     |\n",
            "|    reward               | -0.031321827 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 72.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 128         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 270         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018511191 |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.9       |\n",
            "|    explained_variance   | 0.0557      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 48.6        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    reward               | 0.8328913   |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 79.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 129         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023889791 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.9       |\n",
            "|    explained_variance   | 0.00488     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 33.4        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00591    |\n",
            "|    reward               | -0.44325358 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 57          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 129         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 299         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01734799  |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -43         |\n",
            "|    explained_variance   | 0.0369      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.13        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    reward               | -0.10191948 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 13.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 130         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 313         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020391464 |\n",
            "|    clip_fraction        | 0.197       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -43         |\n",
            "|    explained_variance   | -0.0213     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 28.6        |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00958    |\n",
            "|    reward               | 0.14982384  |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 77.3        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 131        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 328        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02446314 |\n",
            "|    clip_fraction        | 0.225      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -43        |\n",
            "|    explained_variance   | 0.0232     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 53.8       |\n",
            "|    n_updates            | 390        |\n",
            "|    policy_gradient_loss | -0.00251   |\n",
            "|    reward               | -11.140313 |\n",
            "|    std                  | 1.07       |\n",
            "|    value_loss           | 124        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 131         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 342         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.036824152 |\n",
            "|    clip_fraction        | 0.276       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -43.1       |\n",
            "|    explained_variance   | 0.0137      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 12.3        |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.00389    |\n",
            "|    reward               | 3.4458025   |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 24.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 131         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 356         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026212044 |\n",
            "|    clip_fraction        | 0.281       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -43.1       |\n",
            "|    explained_variance   | 0.0222      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 37.7        |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0205     |\n",
            "|    reward               | -0.26940638 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 66.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 371         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.039861396 |\n",
            "|    clip_fraction        | 0.266       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -43.2       |\n",
            "|    explained_variance   | 0.0242      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 47          |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.00556    |\n",
            "|    reward               | 8.1211405   |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 103         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 387         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019900154 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -43.3       |\n",
            "|    explained_variance   | -0.00865    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 53.4        |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.00587    |\n",
            "|    reward               | 1.5889975   |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 90.2        |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=50000) if if_using_ppo else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zpv4S0-fDBv"
      },
      "source": [
        "### Agent 4: TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSAHhV4Xc-bh",
        "outputId": "4a18e366-4c60-4262-cebd-9f291072fdb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cpu device\n",
            "Logging to results/td3\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 100, \n",
        "              \"buffer_size\": 1000000, \n",
        "              \"learning_rate\": 0.001}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
        "\n",
        "if if_using_td3:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/td3'\n",
        "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_td3.set_logger(new_logger_td3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSRxNYAxdKpU",
        "outputId": "5891ff4e-c36e-4ab7-97e7-75ce12630eeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 57       |\n",
            "|    time_elapsed    | 199      |\n",
            "|    total_timesteps | 11572    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 162      |\n",
            "|    critic_loss     | 1.24e+04 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 8679     |\n",
            "|    reward          | 3.151815 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 52       |\n",
            "|    time_elapsed    | 438      |\n",
            "|    total_timesteps | 23144    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 42.6     |\n",
            "|    critic_loss     | 3.05e+03 |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 20251    |\n",
            "|    reward          | 3.151815 |\n",
            "---------------------------------\n",
            "day: 2892, episode: 80\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4548562.25\n",
            "total_reward: 3548562.25\n",
            "total_cost: 1076.89\n",
            "total_trades: 46329\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 52       |\n",
            "|    time_elapsed    | 662      |\n",
            "|    total_timesteps | 34716    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 23.5     |\n",
            "|    critic_loss     | 484      |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 31823    |\n",
            "|    reward          | 3.151815 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 52       |\n",
            "|    time_elapsed    | 886      |\n",
            "|    total_timesteps | 46288    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 20.2     |\n",
            "|    critic_loss     | 39.1     |\n",
            "|    learning_rate   | 0.001    |\n",
            "|    n_updates       | 43395    |\n",
            "|    reward          | 3.151815 |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=50000) if if_using_td3 else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr49PotrfG01"
      },
      "source": [
        "### Agent 5: SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwOhVjqRkCdM",
        "outputId": "bf6bfbf2-251a-4c76-ac72-1730dbc71eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n",
            "Logging to results/sac\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "\n",
        "if if_using_sac:\n",
        "  # set up logger\n",
        "  tmp_path = RESULTS_DIR + '/sac'\n",
        "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "  # Set new logger\n",
        "  model_sac.set_logger(new_logger_sac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8RSdKCckJyH",
        "outputId": "313f9f27-3b80-4b00-d2ce-6bc5ea86ca27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "day: 2892, episode: 90\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3228770.27\n",
            "total_reward: 2228770.27\n",
            "total_cost: 35476.68\n",
            "total_trades: 44660\n",
            "Sharpe: 0.556\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 46        |\n",
            "|    time_elapsed    | 246       |\n",
            "|    total_timesteps | 11572     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 644       |\n",
            "|    critic_loss     | 256       |\n",
            "|    ent_coef        | 0.131     |\n",
            "|    ent_coef_loss   | -61       |\n",
            "|    learning_rate   | 0.0001    |\n",
            "|    n_updates       | 11471     |\n",
            "|    reward          | 4.6760244 |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 46       |\n",
            "|    time_elapsed    | 493      |\n",
            "|    total_timesteps | 23144    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 251      |\n",
            "|    critic_loss     | 55.4     |\n",
            "|    ent_coef        | 0.0426   |\n",
            "|    ent_coef_loss   | -65.4    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 23043    |\n",
            "|    reward          | 5.933971 |\n",
            "---------------------------------\n",
            "day: 2892, episode: 100\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4170280.62\n",
            "total_reward: 3170280.62\n",
            "total_cost: 1904.48\n",
            "total_trades: 41208\n",
            "Sharpe: 0.679\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 46       |\n",
            "|    time_elapsed    | 746      |\n",
            "|    total_timesteps | 34716    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 129      |\n",
            "|    critic_loss     | 9.68     |\n",
            "|    ent_coef        | 0.0145   |\n",
            "|    ent_coef_loss   | -44.3    |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 34615    |\n",
            "|    reward          | 5.905155 |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 45       |\n",
            "|    time_elapsed    | 1019     |\n",
            "|    total_timesteps | 46288    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 79       |\n",
            "|    critic_loss     | 5.67     |\n",
            "|    ent_coef        | 0.00596  |\n",
            "|    ent_coef_loss   | -0.7     |\n",
            "|    learning_rate   | 0.0001   |\n",
            "|    n_updates       | 46187    |\n",
            "|    reward          | 5.750454 |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=50000) if if_using_sac else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2wZgkQXh1jE"
      },
      "source": [
        "## In-sample Performance\n",
        "\n",
        "Assume that the initial capital is $1,000,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEv5KGC8h1jE"
      },
      "source": [
        "### Set turbulence threshold\n",
        "Set the turbulence threshold to be greater than the maximum of insample turbulence data. If current turbulence index is greater than the threshold, then we assume that the current market is volatile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "efwBi84ch1jE"
      },
      "outputs": [],
      "source": [
        "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
        "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHZMBpSqh1jG",
        "outputId": "ff203a99-ab49-4970-810a-645f30fab21c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2893.000000\n",
              "mean       18.824245\n",
              "std         8.489311\n",
              "min         9.140000\n",
              "25%        13.330000\n",
              "50%        16.139999\n",
              "75%        21.309999\n",
              "max        82.690002\n",
              "Name: vix, dtype: float64"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.vix.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDkszkMloRWT",
        "outputId": "3fae2054-33b6-40da-f057-78da8dda3077"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57.40400183105453"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.vix.quantile(0.996)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL7hs7svnNWT",
        "outputId": "7ff675ad-25b8-4d26-ef32-f58237d20b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    2893.000000\n",
              "mean       34.567962\n",
              "std        43.790810\n",
              "min         0.000000\n",
              "25%        14.962540\n",
              "50%        24.123943\n",
              "75%        39.162579\n",
              "max       652.505565\n",
              "Name: turbulence, dtype: float64"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.turbulence.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N78hfHckoqJ9",
        "outputId": "f5e548c1-6891-4209-cbff-0e25b54fc8aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "276.4524526553459"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "insample_risk_indicator.turbulence.quantile(0.996)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5mmgQF_h1jQ"
      },
      "source": [
        "### Trading (Out-of-sample Performance)\n",
        "\n",
        "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
        "\n",
        "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "cIqoV0GSI52v"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "W_XNgGsBMeVw",
        "outputId": "45a92b16-4907-421b-bf48-8b0ff4bff45b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>91.279999</td>\n",
              "      <td>91.839996</td>\n",
              "      <td>90.977501</td>\n",
              "      <td>89.494553</td>\n",
              "      <td>110737200.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.000854</td>\n",
              "      <td>92.276538</td>\n",
              "      <td>79.814266</td>\n",
              "      <td>62.807128</td>\n",
              "      <td>107.498985</td>\n",
              "      <td>29.730532</td>\n",
              "      <td>83.550962</td>\n",
              "      <td>77.363088</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>235.520004</td>\n",
              "      <td>256.230011</td>\n",
              "      <td>232.580002</td>\n",
              "      <td>234.614304</td>\n",
              "      <td>6575800.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.552511</td>\n",
              "      <td>227.036704</td>\n",
              "      <td>195.594648</td>\n",
              "      <td>61.279625</td>\n",
              "      <td>270.848998</td>\n",
              "      <td>46.806139</td>\n",
              "      <td>209.902523</td>\n",
              "      <td>210.950772</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>AXP</td>\n",
              "      <td>95.250000</td>\n",
              "      <td>96.959999</td>\n",
              "      <td>93.639999</td>\n",
              "      <td>91.078468</td>\n",
              "      <td>3301000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.384903</td>\n",
              "      <td>109.215321</td>\n",
              "      <td>86.798779</td>\n",
              "      <td>48.504819</td>\n",
              "      <td>-66.306151</td>\n",
              "      <td>3.142448</td>\n",
              "      <td>96.180265</td>\n",
              "      <td>89.702836</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>BA</td>\n",
              "      <td>185.880005</td>\n",
              "      <td>190.610001</td>\n",
              "      <td>180.039993</td>\n",
              "      <td>180.320007</td>\n",
              "      <td>49036700.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.443193</td>\n",
              "      <td>220.721139</td>\n",
              "      <td>160.932863</td>\n",
              "      <td>50.925771</td>\n",
              "      <td>24.220608</td>\n",
              "      <td>15.932920</td>\n",
              "      <td>176.472335</td>\n",
              "      <td>155.614168</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-07-01</td>\n",
              "      <td>CAT</td>\n",
              "      <td>129.380005</td>\n",
              "      <td>129.399994</td>\n",
              "      <td>125.879997</td>\n",
              "      <td>118.455788</td>\n",
              "      <td>2807800.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.249466</td>\n",
              "      <td>128.246931</td>\n",
              "      <td>111.290116</td>\n",
              "      <td>52.865418</td>\n",
              "      <td>35.692958</td>\n",
              "      <td>14.457404</td>\n",
              "      <td>117.239535</td>\n",
              "      <td>111.578318</td>\n",
              "      <td>28.620001</td>\n",
              "      <td>53.068112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic        open        high         low       close  \\\n",
              "0  2020-07-01  AAPL   91.279999   91.839996   90.977501   89.494553   \n",
              "0  2020-07-01  AMGN  235.520004  256.230011  232.580002  234.614304   \n",
              "0  2020-07-01   AXP   95.250000   96.959999   93.639999   91.078468   \n",
              "0  2020-07-01    BA  185.880005  190.610001  180.039993  180.320007   \n",
              "0  2020-07-01   CAT  129.380005  129.399994  125.879997  118.455788   \n",
              "\n",
              "        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
              "0  110737200.0  2.0  3.000854   92.276538   79.814266  62.807128  107.498985   \n",
              "0    6575800.0  2.0  3.552511  227.036704  195.594648  61.279625  270.848998   \n",
              "0    3301000.0  2.0 -0.384903  109.215321   86.798779  48.504819  -66.306151   \n",
              "0   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   24.220608   \n",
              "0    2807800.0  2.0  1.249466  128.246931  111.290116  52.865418   35.692958   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
              "0  29.730532     83.550962     77.363088  28.620001   53.068112  \n",
              "0  46.806139    209.902523    210.950772  28.620001   53.068112  \n",
              "0   3.142448     96.180265     89.702836  28.620001   53.068112  \n",
              "0  15.932920    176.472335    155.614168  28.620001   53.068112  \n",
              "0  14.457404    117.239535    111.578318  28.620001   53.068112  "
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trade.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbFchno5j3xs",
        "outputId": "946fea4e-15e2-4611-9d14-01364e4ad00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_a2c\n",
        "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
        "    model=trained_moedl, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbYljWGjj3pH",
        "outputId": "65145e7d-15ff-4e62-94f9-e5256297d5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_ddpg\n",
        "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
        "    model=trained_moedl, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74jNP2DBj3hb",
        "outputId": "f20ffd89-2b19-4340-9588-10e64a6b3b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_ppo\n",
        "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
        "    model=trained_moedl, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7VyGGJPj3SH",
        "outputId": "a3b915fb-540f-4540-b0eb-c3ce085d59ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_td3\n",
        "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
        "    model=trained_moedl, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLOnL5eYh1jR",
        "outputId": "0fa13ef0-b55f-4ca1-ac2c-e007913016ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "trained_moedl = trained_sac\n",
        "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
        "    model=trained_moedl, \n",
        "    environment = e_trade_gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERxw3KqLkcP4",
        "outputId": "a969404e-b684-40e4-c0d7-278df230131c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(658, 2)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value_a2c.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcE-t08w6DaW"
      },
      "source": [
        "<a id='7'></a>\n",
        "# Part 6.5: Mean Variance Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_b1vKXKgSe4G",
        "outputId": "660f771e-5fd0-4de6-8a63-ff840357ec43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2.758535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>43.832634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AXP</td>\n",
              "      <td>15.365306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>BA</td>\n",
              "      <td>33.941090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CAT</td>\n",
              "      <td>31.579327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   tic      close\n",
              "0  2009-01-02  AAPL   2.758535\n",
              "1  2009-01-02  AMGN  43.832634\n",
              "2  2009-01-02   AXP  15.365306\n",
              "3  2009-01-02    BA  33.941090\n",
              "4  2009-01-02   CAT  31.579327"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mvo_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2.758535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>43.832634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>AXP</td>\n",
              "      <td>15.365306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>BA</td>\n",
              "      <td>33.941090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>CAT</td>\n",
              "      <td>31.579327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102974</th>\n",
              "      <td>2023-02-09</td>\n",
              "      <td>UNH</td>\n",
              "      <td>485.730011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102975</th>\n",
              "      <td>2023-02-09</td>\n",
              "      <td>V</td>\n",
              "      <td>229.350006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102976</th>\n",
              "      <td>2023-02-09</td>\n",
              "      <td>VZ</td>\n",
              "      <td>39.810001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102977</th>\n",
              "      <td>2023-02-09</td>\n",
              "      <td>WBA</td>\n",
              "      <td>35.342278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102978</th>\n",
              "      <td>2023-02-09</td>\n",
              "      <td>WMT</td>\n",
              "      <td>141.520004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102979 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              date   tic       close\n",
              "0       2009-01-02  AAPL    2.758535\n",
              "1       2009-01-02  AMGN   43.832634\n",
              "2       2009-01-02   AXP   15.365306\n",
              "3       2009-01-02    BA   33.941090\n",
              "4       2009-01-02   CAT   31.579327\n",
              "...            ...   ...         ...\n",
              "102974  2023-02-09   UNH  485.730011\n",
              "102975  2023-02-09     V  229.350006\n",
              "102976  2023-02-09    VZ   39.810001\n",
              "102977  2023-02-09   WBA   35.342278\n",
              "102978  2023-02-09   WMT  141.520004\n",
              "\n",
              "[102979 rows x 3 columns]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mvo_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "fE2YWB0WBDVu"
      },
      "outputs": [],
      "source": [
        "fst = mvo_df\n",
        "fst = fst.iloc[0*29:0*29+29, :]\n",
        "tic = fst['tic'].tolist()\n",
        "\n",
        "mvo = pd.DataFrame()\n",
        "\n",
        "for k in range(len(tic)):\n",
        "  mvo[tic[k]] = 0\n",
        "\n",
        "for i in range(mvo_df.shape[0]//29):\n",
        "  n = mvo_df\n",
        "  n = n.iloc[i*29:i*29+29, :]\n",
        "  date = n['date'][i*29]\n",
        "  mvo.loc[date] = n['close'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K2xfyh_VcXo",
        "outputId": "a5c14ef9-af8a-47c8-f326-d85b0fb78f66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3551"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mvo.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AMGN</th>\n",
              "      <th>AXP</th>\n",
              "      <th>BA</th>\n",
              "      <th>CAT</th>\n",
              "      <th>CRM</th>\n",
              "      <th>CSCO</th>\n",
              "      <th>CVX</th>\n",
              "      <th>DIS</th>\n",
              "      <th>GS</th>\n",
              "      <th>...</th>\n",
              "      <th>MRK</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>NKE</th>\n",
              "      <th>PG</th>\n",
              "      <th>TRV</th>\n",
              "      <th>UNH</th>\n",
              "      <th>V</th>\n",
              "      <th>VZ</th>\n",
              "      <th>WBA</th>\n",
              "      <th>WMT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-01-02</th>\n",
              "      <td>2.758535</td>\n",
              "      <td>43.832634</td>\n",
              "      <td>15.365306</td>\n",
              "      <td>33.941090</td>\n",
              "      <td>31.579327</td>\n",
              "      <td>8.505000</td>\n",
              "      <td>11.948338</td>\n",
              "      <td>43.677189</td>\n",
              "      <td>20.597494</td>\n",
              "      <td>69.747612</td>\n",
              "      <td>...</td>\n",
              "      <td>17.947050</td>\n",
              "      <td>15.162146</td>\n",
              "      <td>11.144301</td>\n",
              "      <td>41.015411</td>\n",
              "      <td>32.030632</td>\n",
              "      <td>22.703100</td>\n",
              "      <td>12.079287</td>\n",
              "      <td>16.240593</td>\n",
              "      <td>17.517094</td>\n",
              "      <td>41.618896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-05</th>\n",
              "      <td>2.874957</td>\n",
              "      <td>44.323048</td>\n",
              "      <td>15.858130</td>\n",
              "      <td>34.631161</td>\n",
              "      <td>31.020584</td>\n",
              "      <td>8.337500</td>\n",
              "      <td>12.054011</td>\n",
              "      <td>43.757122</td>\n",
              "      <td>20.235834</td>\n",
              "      <td>71.371521</td>\n",
              "      <td>...</td>\n",
              "      <td>17.674953</td>\n",
              "      <td>15.303852</td>\n",
              "      <td>11.224109</td>\n",
              "      <td>40.721523</td>\n",
              "      <td>31.555828</td>\n",
              "      <td>22.332808</td>\n",
              "      <td>12.165179</td>\n",
              "      <td>15.227900</td>\n",
              "      <td>18.401514</td>\n",
              "      <td>41.138504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-06</th>\n",
              "      <td>2.827537</td>\n",
              "      <td>43.349655</td>\n",
              "      <td>16.748425</td>\n",
              "      <td>34.736183</td>\n",
              "      <td>30.832092</td>\n",
              "      <td>8.650000</td>\n",
              "      <td>12.533072</td>\n",
              "      <td>44.150948</td>\n",
              "      <td>20.933327</td>\n",
              "      <td>71.315254</td>\n",
              "      <td>...</td>\n",
              "      <td>17.350746</td>\n",
              "      <td>15.482843</td>\n",
              "      <td>10.997277</td>\n",
              "      <td>40.603954</td>\n",
              "      <td>30.592075</td>\n",
              "      <td>21.806171</td>\n",
              "      <td>13.021853</td>\n",
              "      <td>14.984101</td>\n",
              "      <td>18.312380</td>\n",
              "      <td>40.774574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-07</th>\n",
              "      <td>2.766439</td>\n",
              "      <td>43.245621</td>\n",
              "      <td>16.042887</td>\n",
              "      <td>33.573555</td>\n",
              "      <td>29.398203</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>12.201953</td>\n",
              "      <td>42.215961</td>\n",
              "      <td>19.960279</td>\n",
              "      <td>67.930779</td>\n",
              "      <td>...</td>\n",
              "      <td>17.072865</td>\n",
              "      <td>14.550591</td>\n",
              "      <td>10.598215</td>\n",
              "      <td>39.892052</td>\n",
              "      <td>29.380297</td>\n",
              "      <td>21.641596</td>\n",
              "      <td>12.739308</td>\n",
              "      <td>15.174374</td>\n",
              "      <td>18.531778</td>\n",
              "      <td>40.425209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-01-08</th>\n",
              "      <td>2.817809</td>\n",
              "      <td>44.033253</td>\n",
              "      <td>16.066935</td>\n",
              "      <td>33.596058</td>\n",
              "      <td>29.633816</td>\n",
              "      <td>8.227500</td>\n",
              "      <td>12.356951</td>\n",
              "      <td>42.375786</td>\n",
              "      <td>19.719173</td>\n",
              "      <td>68.662315</td>\n",
              "      <td>...</td>\n",
              "      <td>16.997597</td>\n",
              "      <td>15.005531</td>\n",
              "      <td>10.793545</td>\n",
              "      <td>39.454475</td>\n",
              "      <td>29.925962</td>\n",
              "      <td>21.978970</td>\n",
              "      <td>12.603684</td>\n",
              "      <td>15.407464</td>\n",
              "      <td>18.401514</td>\n",
              "      <td>37.397320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-03</th>\n",
              "      <td>154.264465</td>\n",
              "      <td>243.026794</td>\n",
              "      <td>178.860001</td>\n",
              "      <td>206.009995</td>\n",
              "      <td>247.759995</td>\n",
              "      <td>171.039993</td>\n",
              "      <td>48.630001</td>\n",
              "      <td>167.965149</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>369.950012</td>\n",
              "      <td>...</td>\n",
              "      <td>102.940002</td>\n",
              "      <td>257.704529</td>\n",
              "      <td>127.610001</td>\n",
              "      <td>142.610001</td>\n",
              "      <td>182.759995</td>\n",
              "      <td>472.019989</td>\n",
              "      <td>229.680145</td>\n",
              "      <td>41.509998</td>\n",
              "      <td>36.605560</td>\n",
              "      <td>141.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-06</th>\n",
              "      <td>151.498688</td>\n",
              "      <td>241.718353</td>\n",
              "      <td>176.479996</td>\n",
              "      <td>206.809998</td>\n",
              "      <td>251.419998</td>\n",
              "      <td>169.050003</td>\n",
              "      <td>47.570000</td>\n",
              "      <td>168.153488</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>370.799988</td>\n",
              "      <td>...</td>\n",
              "      <td>104.029999</td>\n",
              "      <td>256.128448</td>\n",
              "      <td>125.730003</td>\n",
              "      <td>141.399994</td>\n",
              "      <td>185.990005</td>\n",
              "      <td>475.239990</td>\n",
              "      <td>228.991501</td>\n",
              "      <td>41.279999</td>\n",
              "      <td>35.806137</td>\n",
              "      <td>140.679993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-07</th>\n",
              "      <td>154.414230</td>\n",
              "      <td>241.867035</td>\n",
              "      <td>178.699997</td>\n",
              "      <td>214.759995</td>\n",
              "      <td>249.660004</td>\n",
              "      <td>171.279999</td>\n",
              "      <td>47.840000</td>\n",
              "      <td>172.564484</td>\n",
              "      <td>111.629997</td>\n",
              "      <td>374.399994</td>\n",
              "      <td>...</td>\n",
              "      <td>105.680000</td>\n",
              "      <td>266.891510</td>\n",
              "      <td>125.330002</td>\n",
              "      <td>140.020004</td>\n",
              "      <td>189.009995</td>\n",
              "      <td>476.880005</td>\n",
              "      <td>230.867828</td>\n",
              "      <td>40.549999</td>\n",
              "      <td>36.260132</td>\n",
              "      <td>140.979996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-08</th>\n",
              "      <td>151.688400</td>\n",
              "      <td>238.100250</td>\n",
              "      <td>179.000000</td>\n",
              "      <td>213.500000</td>\n",
              "      <td>248.869995</td>\n",
              "      <td>169.630005</td>\n",
              "      <td>46.959999</td>\n",
              "      <td>168.510330</td>\n",
              "      <td>111.779999</td>\n",
              "      <td>375.100006</td>\n",
              "      <td>...</td>\n",
              "      <td>106.639999</td>\n",
              "      <td>266.063599</td>\n",
              "      <td>122.910004</td>\n",
              "      <td>138.570007</td>\n",
              "      <td>187.389999</td>\n",
              "      <td>483.220001</td>\n",
              "      <td>229.750000</td>\n",
              "      <td>40.520000</td>\n",
              "      <td>36.082481</td>\n",
              "      <td>140.220001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-09</th>\n",
              "      <td>150.639999</td>\n",
              "      <td>237.901993</td>\n",
              "      <td>179.369995</td>\n",
              "      <td>211.990005</td>\n",
              "      <td>246.279999</td>\n",
              "      <td>173.660004</td>\n",
              "      <td>46.730000</td>\n",
              "      <td>166.964005</td>\n",
              "      <td>110.360001</td>\n",
              "      <td>367.989990</td>\n",
              "      <td>...</td>\n",
              "      <td>106.720001</td>\n",
              "      <td>262.961365</td>\n",
              "      <td>122.180000</td>\n",
              "      <td>137.050003</td>\n",
              "      <td>185.360001</td>\n",
              "      <td>485.730011</td>\n",
              "      <td>229.350006</td>\n",
              "      <td>39.810001</td>\n",
              "      <td>35.342278</td>\n",
              "      <td>141.520004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3551 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  AAPL        AMGN         AXP          BA         CAT  \\\n",
              "2009-01-02    2.758535   43.832634   15.365306   33.941090   31.579327   \n",
              "2009-01-05    2.874957   44.323048   15.858130   34.631161   31.020584   \n",
              "2009-01-06    2.827537   43.349655   16.748425   34.736183   30.832092   \n",
              "2009-01-07    2.766439   43.245621   16.042887   33.573555   29.398203   \n",
              "2009-01-08    2.817809   44.033253   16.066935   33.596058   29.633816   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2023-02-03  154.264465  243.026794  178.860001  206.009995  247.759995   \n",
              "2023-02-06  151.498688  241.718353  176.479996  206.809998  251.419998   \n",
              "2023-02-07  154.414230  241.867035  178.699997  214.759995  249.660004   \n",
              "2023-02-08  151.688400  238.100250  179.000000  213.500000  248.869995   \n",
              "2023-02-09  150.639999  237.901993  179.369995  211.990005  246.279999   \n",
              "\n",
              "                   CRM       CSCO         CVX         DIS          GS  ...  \\\n",
              "2009-01-02    8.505000  11.948338   43.677189   20.597494   69.747612  ...   \n",
              "2009-01-05    8.337500  12.054011   43.757122   20.235834   71.371521  ...   \n",
              "2009-01-06    8.650000  12.533072   44.150948   20.933327   71.315254  ...   \n",
              "2009-01-07    8.000000  12.201953   42.215961   19.960279   67.930779  ...   \n",
              "2009-01-08    8.227500  12.356951   42.375786   19.719173   68.662315  ...   \n",
              "...                ...        ...         ...         ...         ...  ...   \n",
              "2023-02-03  171.039993  48.630001  167.965149  110.709999  369.950012  ...   \n",
              "2023-02-06  169.050003  47.570000  168.153488  109.870003  370.799988  ...   \n",
              "2023-02-07  171.279999  47.840000  172.564484  111.629997  374.399994  ...   \n",
              "2023-02-08  169.630005  46.959999  168.510330  111.779999  375.100006  ...   \n",
              "2023-02-09  173.660004  46.730000  166.964005  110.360001  367.989990  ...   \n",
              "\n",
              "                   MRK        MSFT         NKE          PG         TRV  \\\n",
              "2009-01-02   17.947050   15.162146   11.144301   41.015411   32.030632   \n",
              "2009-01-05   17.674953   15.303852   11.224109   40.721523   31.555828   \n",
              "2009-01-06   17.350746   15.482843   10.997277   40.603954   30.592075   \n",
              "2009-01-07   17.072865   14.550591   10.598215   39.892052   29.380297   \n",
              "2009-01-08   16.997597   15.005531   10.793545   39.454475   29.925962   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2023-02-03  102.940002  257.704529  127.610001  142.610001  182.759995   \n",
              "2023-02-06  104.029999  256.128448  125.730003  141.399994  185.990005   \n",
              "2023-02-07  105.680000  266.891510  125.330002  140.020004  189.009995   \n",
              "2023-02-08  106.639999  266.063599  122.910004  138.570007  187.389999   \n",
              "2023-02-09  106.720001  262.961365  122.180000  137.050003  185.360001   \n",
              "\n",
              "                   UNH           V         VZ        WBA         WMT  \n",
              "2009-01-02   22.703100   12.079287  16.240593  17.517094   41.618896  \n",
              "2009-01-05   22.332808   12.165179  15.227900  18.401514   41.138504  \n",
              "2009-01-06   21.806171   13.021853  14.984101  18.312380   40.774574  \n",
              "2009-01-07   21.641596   12.739308  15.174374  18.531778   40.425209  \n",
              "2009-01-08   21.978970   12.603684  15.407464  18.401514   37.397320  \n",
              "...                ...         ...        ...        ...         ...  \n",
              "2023-02-03  472.019989  229.680145  41.509998  36.605560  141.710007  \n",
              "2023-02-06  475.239990  228.991501  41.279999  35.806137  140.679993  \n",
              "2023-02-07  476.880005  230.867828  40.549999  36.260132  140.979996  \n",
              "2023-02-08  483.220001  229.750000  40.520000  36.082481  140.220001  \n",
              "2023-02-09  485.730011  229.350006  39.810001  35.342278  141.520004  \n",
              "\n",
              "[3551 rows x 29 columns]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mvo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwEwkHJ1d_6u"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeVVbuwveJ_5"
      },
      "source": [
        "### Calculate mean returns and variance-covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2G1phEm_Ut3",
        "outputId": "88d98b75-449e-49b6-b4bb-3407dd53a7ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 89.495, 234.614,  91.078, ...,  47.767,  36.29 , 115.097],\n",
              "       [ 89.495, 237.484,  91.35 , ...,  47.872,  37.267, 114.636],\n",
              "       [ 91.889, 235.654,  93.529, ...,  48.265,  38.314, 114.328],\n",
              "       ...,\n",
              "       [154.414, 241.867, 178.7  , ...,  40.55 ,  36.26 , 140.98 ],\n",
              "       [151.688, 238.1  , 179.   , ...,  40.52 ,  36.082, 140.22 ],\n",
              "       [150.64 , 237.902, 179.37 , ...,  39.81 ,  35.342, 141.52 ]])"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtain optimal portfolio sets that maximize return and minimize risk\n",
        "\n",
        "#Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#input k-portfolio 1 dataset comprising 15 stocks\n",
        "# StockFileName = './DJIA_Apr112014_Apr112019_kpf1.csv'\n",
        "\n",
        "Rows = int(len(mvo_df)/29)  #excluding header \n",
        "Columns = 15  #excluding date\n",
        "portfolioSize = 29 #set portfolio size\n",
        "\n",
        "\n",
        "#read stock prices in a dataframe\n",
        "# df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "\n",
        "#extract asset labels\n",
        "# assetLabels = df.columns[1:Columns+1].tolist()\n",
        "# print(assetLabels)\n",
        "\n",
        "#extract asset prices\n",
        "# StockData = df.iloc[0:, 1:]\n",
        "StockData = mvo.head(mvo.shape[0]-int(len(trade)))\n",
        "TradeData = mvo.tail(int(len(trade)))\n",
        "# df.head()\n",
        "TradeData.to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_O6vrn_uD4",
        "outputId": "06b9933d-9217-44a0-f800-43764acdcda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean returns of assets in k-portfolio 1\n",
            " [0.136 0.068 0.086 0.083 0.066 0.134 0.06  0.035 0.072 0.056 0.103 0.073\n",
            " 0.033 0.076 0.047 0.073 0.042 0.056 0.054 0.056 0.103 0.089 0.041 0.053\n",
            " 0.104 0.11  0.044 0.042 0.042]\n",
            "Variance-Covariance matrix of returns\n",
            " [[3.156 1.066 1.768 1.669 1.722 1.814 1.569 1.302 1.302 1.811 1.303 1.432\n",
            "  1.218 1.674 0.74  1.839 0.719 0.884 1.241 0.823 1.561 1.324 0.752 1.027\n",
            "  1.298 1.466 0.657 1.078 0.631]\n",
            " [1.066 2.571 1.306 1.123 1.193 1.319 1.116 1.053 1.045 1.269 1.068 1.089\n",
            "  0.899 1.218 0.926 1.391 0.682 0.727 1.025 1.156 1.166 0.984 0.798 0.956\n",
            "  1.259 1.111 0.688 1.091 0.682]\n",
            " [1.768 1.306 4.847 2.73  2.6   2.128 1.944 2.141 2.17  3.142 1.932 2.283\n",
            "  1.56  2.012 0.993 3.707 1.094 1.319 1.845 1.236 1.899 1.894 1.041 1.921\n",
            "  1.823 2.314 0.986 1.421 0.707]\n",
            " [1.669 1.123 2.73  4.892 2.363 1.979 1.7   2.115 1.959 2.387 1.773 2.319\n",
            "  1.571 1.797 0.968 2.597 1.144 1.298 1.643 1.071 1.615 1.775 0.91  1.666\n",
            "  1.707 1.784 0.82  1.345 0.647]\n",
            " [1.722 1.193 2.6   2.363 4.019 2.127 1.917 2.059 1.817 2.46  1.577 2.238\n",
            "  1.513 1.929 0.925 2.64  0.947 0.971 1.894 1.089 1.711 1.642 0.865 1.456\n",
            "  1.478 1.687 0.92  1.326 0.697]\n",
            " [1.814 1.319 2.128 1.979 2.127 5.384 1.974 1.549 1.683 2.122 1.624 1.771\n",
            "  1.441 1.939 0.846 2.191 0.837 1.075 1.475 1.041 1.978 1.768 0.784 1.328\n",
            "  1.365 1.912 0.787 1.28  0.666]\n",
            " [1.569 1.116 1.944 1.7   1.917 1.974 3.081 1.483 1.534 1.937 1.367 1.62\n",
            "  1.399 1.843 0.894 2.057 0.794 0.905 1.438 1.014 1.72  1.382 0.865 1.206\n",
            "  1.273 1.488 0.811 1.173 0.753]\n",
            " [1.302 1.053 2.141 2.115 2.059 1.549 1.483 2.842 1.525 2.044 1.428 1.783\n",
            "  1.308 1.533 0.878 2.279 0.938 1.092 1.385 1.078 1.429 1.314 0.831 1.459\n",
            "  1.466 1.48  0.83  1.042 0.567]\n",
            " [1.302 1.045 2.17  1.959 1.817 1.683 1.534 1.525 2.661 1.987 1.454 1.748\n",
            "  1.217 1.475 0.791 2.216 0.896 0.973 1.396 0.949 1.379 1.407 0.859 1.268\n",
            "  1.281 1.454 0.81  1.143 0.667]\n",
            " [1.811 1.269 3.142 2.387 2.46  2.122 1.937 2.044 1.987 4.407 1.789 2.12\n",
            "  1.593 1.982 0.945 3.96  0.956 1.094 1.758 1.157 1.788 1.692 0.905 1.879\n",
            "  1.712 2.    0.945 1.421 0.713]\n",
            " [1.303 1.068 1.932 1.773 1.577 1.624 1.367 1.428 1.454 1.789 2.373 1.51\n",
            "  1.166 1.501 0.756 1.941 0.824 0.998 1.239 0.887 1.366 1.414 0.797 1.299\n",
            "  1.296 1.41  0.764 1.071 0.783]\n",
            " [1.432 1.089 2.283 2.319 2.238 1.771 1.62  1.783 1.748 2.12  1.51  2.516\n",
            "  1.326 1.575 0.889 2.345 0.958 1.022 1.623 1.02  1.489 1.532 0.848 1.377\n",
            "  1.444 1.547 0.81  1.211 0.63 ]\n",
            " [1.218 0.899 1.56  1.571 1.513 1.441 1.399 1.308 1.217 1.593 1.166 1.326\n",
            "  2.052 1.399 0.727 1.749 0.786 0.795 1.154 0.829 1.296 1.12  0.743 1.105\n",
            "  1.088 1.214 0.739 0.998 0.598]\n",
            " [1.674 1.218 2.012 1.797 1.929 1.939 1.843 1.533 1.475 1.982 1.501 1.575\n",
            "  1.399 3.289 0.853 2.112 0.85  0.89  1.412 1.002 1.9   1.352 0.842 1.317\n",
            "  1.334 1.487 0.847 1.165 0.766]\n",
            " [0.74  0.926 0.993 0.968 0.925 0.846 0.894 0.878 0.791 0.945 0.756 0.889\n",
            "  0.727 0.853 1.153 1.027 0.642 0.59  0.848 0.892 0.825 0.748 0.694 0.761\n",
            "  0.929 0.819 0.61  0.806 0.547]\n",
            " [1.839 1.391 3.707 2.597 2.64  2.191 2.057 2.279 2.216 3.96  1.941 2.345\n",
            "  1.749 2.112 1.027 5.271 1.08  1.235 1.892 1.297 1.91  1.85  1.068 2.164\n",
            "  1.85  2.169 1.112 1.555 0.779]\n",
            " [0.719 0.682 1.094 1.144 0.947 0.837 0.794 0.938 0.896 0.956 0.824 0.958\n",
            "  0.786 0.85  0.642 1.08  1.264 0.679 0.804 0.74  0.819 0.845 0.749 0.891\n",
            "  0.849 0.794 0.633 0.719 0.514]\n",
            " [0.884 0.727 1.319 1.298 0.971 1.075 0.905 1.092 0.973 1.094 0.998 1.022\n",
            "  0.795 0.89  0.59  1.235 0.679 1.518 0.816 0.719 0.943 1.027 0.615 1.\n",
            "  0.947 0.994 0.533 0.673 0.504]\n",
            " [1.241 1.025 1.845 1.643 1.894 1.475 1.438 1.385 1.396 1.758 1.239 1.623\n",
            "  1.154 1.412 0.848 1.892 0.804 0.816 2.028 0.9   1.265 1.243 0.787 1.194\n",
            "  1.193 1.282 0.752 1.099 0.622]\n",
            " [0.823 1.156 1.236 1.071 1.089 1.041 1.014 1.078 0.949 1.157 0.887 1.02\n",
            "  0.829 1.002 0.892 1.297 0.74  0.719 0.9   2.007 0.952 0.849 0.732 1.008\n",
            "  1.15  0.933 0.722 0.897 0.614]\n",
            " [1.561 1.166 1.899 1.615 1.711 1.978 1.72  1.429 1.379 1.788 1.366 1.489\n",
            "  1.296 1.9   0.825 1.91  0.819 0.943 1.265 0.952 2.759 1.308 0.832 1.214\n",
            "  1.285 1.493 0.793 1.113 0.705]\n",
            " [1.324 0.984 1.894 1.775 1.642 1.768 1.382 1.314 1.407 1.692 1.414 1.532\n",
            "  1.12  1.352 0.748 1.85  0.845 1.027 1.243 0.849 1.308 2.864 0.751 1.153\n",
            "  1.26  1.411 0.71  1.046 0.651]\n",
            " [0.752 0.798 1.041 0.91  0.865 0.784 0.865 0.831 0.859 0.905 0.797 0.848\n",
            "  0.743 0.842 0.694 1.068 0.749 0.615 0.787 0.732 0.832 0.751 1.289 0.806\n",
            "  0.766 0.763 0.663 0.797 0.645]\n",
            " [1.027 0.956 1.921 1.666 1.456 1.328 1.206 1.459 1.268 1.879 1.299 1.377\n",
            "  1.105 1.317 0.761 2.164 0.891 1.    1.194 1.008 1.214 1.153 0.806 2.27\n",
            "  1.259 1.294 0.812 0.986 0.676]\n",
            " [1.298 1.259 1.823 1.707 1.478 1.365 1.273 1.466 1.281 1.712 1.296 1.444\n",
            "  1.088 1.334 0.929 1.85  0.849 0.947 1.193 1.15  1.285 1.26  0.766 1.259\n",
            "  3.352 1.267 0.697 1.137 0.685]\n",
            " [1.466 1.111 2.314 1.784 1.687 1.912 1.488 1.48  1.454 2.    1.41  1.547\n",
            "  1.214 1.487 0.819 2.169 0.794 0.994 1.282 0.933 1.493 1.411 0.763 1.294\n",
            "  1.267 2.982 0.709 1.007 0.656]\n",
            " [0.657 0.688 0.986 0.82  0.92  0.787 0.811 0.83  0.81  0.945 0.764 0.81\n",
            "  0.739 0.847 0.61  1.112 0.633 0.533 0.752 0.722 0.793 0.71  0.663 0.812\n",
            "  0.697 0.709 1.371 0.697 0.561]\n",
            " [1.078 1.091 1.421 1.345 1.326 1.28  1.173 1.042 1.143 1.421 1.071 1.211\n",
            "  0.998 1.165 0.806 1.555 0.719 0.673 1.099 0.897 1.113 1.046 0.797 0.986\n",
            "  1.137 1.007 0.697 3.073 0.759]\n",
            " [0.631 0.682 0.707 0.647 0.697 0.666 0.753 0.567 0.667 0.713 0.783 0.63\n",
            "  0.598 0.766 0.547 0.779 0.514 0.504 0.622 0.614 0.705 0.651 0.645 0.676\n",
            "  0.685 0.656 0.561 0.759 1.452]]\n"
          ]
        }
      ],
      "source": [
        "#compute asset returns\n",
        "arStockPrices = np.asarray(StockData)\n",
        "[Rows, Cols]=arStockPrices.shape\n",
        "arReturns = helper.StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "\n",
        "\n",
        "#compute mean returns and variance covariance matrix of returns\n",
        "meanReturns = np.mean(arReturns, axis = 0)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        " \n",
        "#set precision for printing results\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "#display mean returns and variance-covariance matrix of returns\n",
        "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
        "print('Variance-Covariance matrix of returns\\n', covReturns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1btTONEdCU4",
        "outputId": "13830f03-0872-4991-94c4-e9d1d2e4cd4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([424250.,      0.,      0.,      0.,      0., 108650.,      0.,\n",
              "            0.,      0.,      0., 181450.,      0.,      0.,      0.,\n",
              "            0.,      0.,      0.,      0.,      0.,      0.,  16960.,\n",
              "            0.,      0.,      0., 133540., 135150.,      0.,      0.,\n",
              "            0.])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from module.efficient_frontier import EfficientFrontier\n",
        "\n",
        "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
        "raw_weights_mean = ef_mean.max_sharpe()\n",
        "cleaned_weights_mean = ef_mean.clean_weights()\n",
        "mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\n",
        "mvo_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "N6tTAjAvgFtO",
        "outputId": "58b6be0e-cd87-4965-fdf6-5b66b1fd1221"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AMGN</th>\n",
              "      <th>AXP</th>\n",
              "      <th>BA</th>\n",
              "      <th>CAT</th>\n",
              "      <th>CRM</th>\n",
              "      <th>CSCO</th>\n",
              "      <th>CVX</th>\n",
              "      <th>DIS</th>\n",
              "      <th>GS</th>\n",
              "      <th>...</th>\n",
              "      <th>MRK</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>NKE</th>\n",
              "      <th>PG</th>\n",
              "      <th>TRV</th>\n",
              "      <th>UNH</th>\n",
              "      <th>V</th>\n",
              "      <th>VZ</th>\n",
              "      <th>WBA</th>\n",
              "      <th>WMT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-06-30</th>\n",
              "      <td>89.664169</td>\n",
              "      <td>216.90239</td>\n",
              "      <td>91.775711</td>\n",
              "      <td>183.300003</td>\n",
              "      <td>118.86924</td>\n",
              "      <td>187.330002</td>\n",
              "      <td>42.848248</td>\n",
              "      <td>78.808449</td>\n",
              "      <td>111.510002</td>\n",
              "      <td>187.060165</td>\n",
              "      <td>...</td>\n",
              "      <td>67.950195</td>\n",
              "      <td>198.444733</td>\n",
              "      <td>95.878021</td>\n",
              "      <td>111.771385</td>\n",
              "      <td>107.692001</td>\n",
              "      <td>284.97879</td>\n",
              "      <td>189.604019</td>\n",
              "      <td>48.16901</td>\n",
              "      <td>37.630482</td>\n",
              "      <td>115.184006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 AAPL       AMGN        AXP          BA        CAT  \\\n",
              "2020-06-30  89.664169  216.90239  91.775711  183.300003  118.86924   \n",
              "\n",
              "                   CRM       CSCO        CVX         DIS          GS  ...  \\\n",
              "2020-06-30  187.330002  42.848248  78.808449  111.510002  187.060165  ...   \n",
              "\n",
              "                  MRK        MSFT        NKE          PG         TRV  \\\n",
              "2020-06-30  67.950195  198.444733  95.878021  111.771385  107.692001   \n",
              "\n",
              "                  UNH           V        VZ        WBA         WMT  \n",
              "2020-06-30  284.97879  189.604019  48.16901  37.630482  115.184006  \n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "StockData.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F38NJRJJgOmj",
        "outputId": "edae2b4d-44a1-47fc-907e-de546c471875"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4731.544,    0.   ,    0.   ,    0.   ,    0.   ,  579.993,\n",
              "          0.   ,    0.   ,    0.   ,    0.   ,  766.211,    0.   ,\n",
              "          0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,\n",
              "          0.   ,    0.   ,   85.465,    0.   ,    0.   ,    0.   ,\n",
              "        468.596,  712.801,    0.   ,    0.   ,    0.   ])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
        "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
        "Initial_Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZAd1iXqZhQ6X",
        "outputId": "1c802633-fc86-415b-ed56-47330c310eb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean Var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-07-01</th>\n",
              "      <td>1.001917e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-02</th>\n",
              "      <td>1.004234e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-06</th>\n",
              "      <td>1.023225e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-07</th>\n",
              "      <td>1.014021e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-08</th>\n",
              "      <td>1.029461e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-03</th>\n",
              "      <td>1.490038e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-06</th>\n",
              "      <td>1.474972e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-07</th>\n",
              "      <td>1.489967e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-08</th>\n",
              "      <td>1.474837e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-09</th>\n",
              "      <td>1.468825e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>658 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Mean Var\n",
              "2020-07-01  1.001917e+06\n",
              "2020-07-02  1.004234e+06\n",
              "2020-07-06  1.023225e+06\n",
              "2020-07-07  1.014021e+06\n",
              "2020-07-08  1.029461e+06\n",
              "...                  ...\n",
              "2023-02-03  1.490038e+06\n",
              "2023-02-06  1.474972e+06\n",
              "2023-02-07  1.489967e+06\n",
              "2023-02-08  1.474837e+06\n",
              "2023-02-09  1.468825e+06\n",
              "\n",
              "[658 rows x 1 columns]"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
        "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
        "MVO_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtesting Results\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "KeDeGAc9VrEg"
      },
      "outputs": [],
      "source": [
        "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
        "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
        "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
        "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
        "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
        "\n",
        "result = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True)\n",
        "result = pd.merge(result, df_result_td3, left_index=True, right_index=True)\n",
        "result = pd.merge(result, df_result_ppo, left_index=True, right_index=True)\n",
        "result = pd.merge(result, df_result_sac, left_index=True, right_index=True)\n",
        "result = pd.merge(result, MVO_result, left_index=True, right_index=True)\n",
        "result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6xRfrqK4RVfq",
        "outputId": "868e3da5-3df9-4d54-b181-f630093210f2"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure()\n",
        "result.plot()\n",
        "plt.savefig(\"trained_models/models_\" + \".jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a2c</th>\n",
              "      <th>ddpg</th>\n",
              "      <th>td3</th>\n",
              "      <th>ppo</th>\n",
              "      <th>sac</th>\n",
              "      <th>mean var</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-09</th>\n",
              "      <td>1.383442e+06</td>\n",
              "      <td>1.251458e+06</td>\n",
              "      <td>1.328701e+06</td>\n",
              "      <td>1.417191e+06</td>\n",
              "      <td>1.493857e+06</td>\n",
              "      <td>1.468825e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     a2c          ddpg           td3           ppo  \\\n",
              "date                                                                 \n",
              "2023-02-09  1.383442e+06  1.251458e+06  1.328701e+06  1.417191e+06   \n",
              "\n",
              "                     sac      mean var  \n",
              "date                                    \n",
              "2023-02-09  1.493857e+06  1.468825e+06  "
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-07-01</th>\n",
              "      <td>1.001917e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-02</th>\n",
              "      <td>1.004234e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-06</th>\n",
              "      <td>1.023225e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-07</th>\n",
              "      <td>1.014021e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-08</th>\n",
              "      <td>1.029461e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-03</th>\n",
              "      <td>1.490038e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-06</th>\n",
              "      <td>1.474972e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-07</th>\n",
              "      <td>1.489967e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-08</th>\n",
              "      <td>1.474837e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-02-09</th>\n",
              "      <td>1.468825e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>658 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            account_value\n",
              "date                     \n",
              "2020-07-01   1.001917e+06\n",
              "2020-07-02   1.004234e+06\n",
              "2020-07-06   1.023225e+06\n",
              "2020-07-07   1.014021e+06\n",
              "2020-07-08   1.029461e+06\n",
              "...                   ...\n",
              "2023-02-03   1.490038e+06\n",
              "2023-02-06   1.474972e+06\n",
              "2023-02-07   1.489967e+06\n",
              "2023-02-08   1.474837e+06\n",
              "2023-02-09   1.468825e+06\n",
              "\n",
              "[658 rows x 1 columns]"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MVO_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MVO_result['account_value'] = MVO_result['Mean Var']\n",
        "MVO_result = MVO_result.drop(\"Mean Var\", axis=1)\n",
        "MVO_result.index.name='date'\n",
        "MVO_result['date'] = MVO_result.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annual return          0.166156\n",
            "Cumulative returns     0.493857\n",
            "Annual volatility      0.185149\n",
            "Sharpe ratio           0.924061\n",
            "Calmar ratio           0.721552\n",
            "Stability              0.348040\n",
            "Max drawdown          -0.230276\n",
            "Omega ratio            1.165591\n",
            "Sortino ratio          1.373467\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.034576\n",
            "Daily value at risk   -0.022648\n",
            "dtype: float64\n",
            "Annual return          0.089703\n",
            "Cumulative returns     0.251458\n",
            "Annual volatility      0.170235\n",
            "Sharpe ratio           0.590576\n",
            "Calmar ratio           0.390584\n",
            "Stability              0.112480\n",
            "Max drawdown          -0.229665\n",
            "Omega ratio            1.104479\n",
            "Sortino ratio          0.839012\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.940607\n",
            "Daily value at risk   -0.021049\n",
            "dtype: float64\n",
            "Annual return          0.142862\n",
            "Cumulative returns     0.417191\n",
            "Annual volatility      0.213350\n",
            "Sharpe ratio           0.733649\n",
            "Calmar ratio           0.523638\n",
            "Stability              0.305047\n",
            "Max drawdown          -0.272826\n",
            "Omega ratio            1.134311\n",
            "Sortino ratio          1.058323\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.061809\n",
            "Daily value at risk   -0.026258\n",
            "dtype: float64\n",
            "Annual return          0.114987\n",
            "Cumulative returns     0.328701\n",
            "Annual volatility      0.176960\n",
            "Sharpe ratio           0.704608\n",
            "Calmar ratio           0.466839\n",
            "Stability              0.209928\n",
            "Max drawdown          -0.246311\n",
            "Omega ratio            1.125276\n",
            "Sortino ratio          1.007236\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.045951\n",
            "Daily value at risk   -0.021800\n",
            "dtype: float64\n",
            "Annual return          0.132361\n",
            "Cumulative returns     0.383442\n",
            "Annual volatility      0.156058\n",
            "Sharpe ratio           0.875848\n",
            "Calmar ratio           0.944337\n",
            "Stability              0.767233\n",
            "Max drawdown          -0.140163\n",
            "Omega ratio            1.157068\n",
            "Sortino ratio          1.283162\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.986292\n",
            "Daily value at risk   -0.019119\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_sac = helper.backtest_stats(account_value = df_account_value_sac)\n",
        "perf_stats_sac = pd.DataFrame(perf_stats_sac)\n",
        "\n",
        "perf_stats_ddpg = helper.backtest_stats(account_value = df_account_value_ddpg)\n",
        "perf_stats_ddpg = pd.DataFrame(perf_stats_ddpg)\n",
        "\n",
        "perf_stats_ppo = helper.backtest_stats(account_value = df_account_value_ppo)\n",
        "perf_stats_ppo = pd.DataFrame(perf_stats_ppo)\n",
        "\n",
        "perf_stats_td3 = helper.backtest_stats(account_value = df_account_value_td3)\n",
        "perf_stats_td3 = pd.DataFrame(perf_stats_td3)\n",
        "\n",
        "perf_stats_a2c = helper.backtest_stats(account_value = df_account_value_a2c)\n",
        "perf_stats_a2c = pd.DataFrame(perf_stats_a2c)\n",
        "\n",
        "perf_stats_mvo = helper.backtest_stats(account_value = MVO_result)\n",
        "perf_stats_mvo = pd.DataFrame(perf_stats_mvo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (658, 8)\n",
            "Annual return          0.108788\n",
            "Cumulative returns     0.309497\n",
            "Annual volatility      0.164130\n",
            "Sharpe ratio           0.712314\n",
            "Calmar ratio           0.495826\n",
            "Stability              0.243378\n",
            "Max drawdown          -0.219408\n",
            "Omega ratio            1.127036\n",
            "Sortino ratio          1.016757\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.968538\n",
            "Daily value at risk   -0.020214\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "baseline_df = YahooDownloader(\n",
        "        ticker_list =[\"^DJI\"], \n",
        "        start_date = TRADE_START_DATE,\n",
        "        end_date = TRADE_END_DATE).fetch_data()\n",
        "\n",
        "stats = helper.backtest_stats(baseline_df, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "Annual_return_sac = perf_stats_sac.T['Annual return'][0]\n",
        "Annual_return_ppo = perf_stats_ppo.T['Annual return'][0]\n",
        "Annual_return_td3 = perf_stats_td3.T['Annual return'][0]\n",
        "Annual_return_ddpg = perf_stats_ddpg.T['Annual return'][0]\n",
        "Annual_return_a2c = perf_stats_a2c.T['Annual return'][0]\n",
        "Annual_return_mvo = perf_stats_mvo.T['Annual return'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_best_model():\n",
        "\n",
        "    Models = []\n",
        "    if Annual_return_sac >= Annual_return_mvo:\n",
        "        Models.append(trained_sac)\n",
        "        \n",
        "    elif Annual_return_a2c >= Annual_return_mvo:\n",
        "        Models.append(trained_a2c)\n",
        "\n",
        "    elif Annual_return_ddpg >= Annual_return_mvo:\n",
        "        Models.append(trained_ddpg)\n",
        "\n",
        "    elif Annual_return_ppo >= Annual_return_mvo:\n",
        "        Models.append(trained_ppo)\n",
        "\n",
        "    elif Annual_return_td3 >= Annual_return_mvo:\n",
        "        Models.append(trained_td3)\n",
        "\n",
        "    return Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "YESTERDAY = datetime.datetime.today() - datetime.timedelta(days=1)\n",
        "DELTA = -(datetime.datetime.strptime('2009-01-01', '%Y-%M-%d') - YESTERDAY).days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datetime.datetime(2020, 4, 26, 8, 21, 46, 308468)"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "YESTERDAY - datetime.timedelta(days=DELTA*0.2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMNR5nHjh1iz",
        "uijiWgkuh1jB",
        "MRiOtrywfAo1",
        "_gDkU-j-fCmZ",
        "3Zpv4S0-fDBv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
